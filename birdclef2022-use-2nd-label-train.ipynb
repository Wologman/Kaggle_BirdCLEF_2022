{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Training Notebook for BirdCLEF2022 ##\n","\n","[Original baseline by Kaerururu](https://www.kaggle.com/code/kaerunantoka/birdclef2022-use-2nd-label-f0/notebook)  \n","[That was forked from Kidehisa Arai (2021 comp)](https://www.kaggle.com/code/hidehisaarai1213/pytorch-inference-birdclef2021-starter/notebook)  \n","[My inference notebook](https://www.kaggle.com/code/ollypowell/birdclef2022-ex005-f0-infer/)  \n","[Original Infernence fork](https://www.kaggle.com/code/kaerunantoka/birdclef2022-ex005-f0-infer/notebook)\n","\n","Data:  \n","https://www.kaggle.com/kaerunantoka/birdclef2022-audio-to-numpy-1-4  \n","https://www.kaggle.com/kaerunantoka/birdclef2022-audio-to-numpy-2-4  \n","https://www.kaggle.com/kaerunantoka/birdclef2022-audio-to-numpy-3-4  \n","https://www.kaggle.com/kaerunantoka/birdclef2022-audio-to-numpy-4-4  \n","\n","\n","**My Strategy:**  \n","1. Set up the training notebook on my own GPU, so no time limits\n","2. Run with all folds, while I work on next step.  Run inference on Kaggle once the models are ready.\n","3. Improve my CV score as much as I can by doing data augmentation, starting with the basic strategies below from Shinmaru, use 128 image size to speed up if need be.  \n","2. Train on additional folds\n","3. Fine tune the inference threshold (Should be in the vacinity of .005 to 0.1)\n","\n","[**Basic Augmentation strategies, suggested to be useful by Shinmaru:**](https://www.kaggle.com/competitions/birdclef-2022/discussion/324318)\n","\n","* Time shift\n","* Add pink noise and brown noise\n","* Mix other audio dataset\n","\n","[Good notebook on this topic by Hidehisa Arai](https://www.kaggle.com/code/hidehisaarai1213/rfcx-audio-data-augmentation-japanese-english)  \n","[Time and noise only covered by Shinmaru](https://www.kaggle.com/code/shinmurashinmura/birdclef2022-basic-augmentation/notebook)\n","\n","[**More advanced ideas (also suggested to work from Shinmaru)**](https://www.kaggle.com/competitions/birdclef-2022/discussion/307880)  \n","\n","[SpecAugment](https://arxiv.org/abs/1904.08779)  \n","[SpecAugment++](https://arxiv.org/abs/2103.16858v3)  \n","[ImportantAug](https://arxiv.org/abs/2112.07156)"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","import sys\n","sys.path.append('input/pytorch-image-models/pytorch-image-models-master')  # removed ../\n","import random\n","import time\n","import librosa\n","import colorednoise as cn\n","import numpy as np\n","import pandas as pd\n","import timm\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn import metrics\n","from torchlibrosa.augmentation import SpecAugmentation\n","from tqdm import tqdm\n","import ast\n","import glob \n","import albumentations as A\n","import transformers\n","from torch.cuda.amp import autocast, GradScaler"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Setup complete. Using torch 1.11.0 _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060 Laptop GPU', major=8, minor=6, total_memory=5946MB, multi_processor_count=30)\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["14852"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Changed the paths to suit my own filenames\n","all_path = glob.glob('input/train_np_1/*/*.npy')\\\n","+ glob.glob('input/train_np_2/*/*.npy')\\\n","+ glob.glob('input/train_np_3/*/*.npy')\\\n","+ glob.glob('input/train_np_4/*/*.npy')\n","\n","len(all_path)"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>primary_label</th>\n","      <th>secondary_labels</th>\n","      <th>type</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>scientific_name</th>\n","      <th>common_name</th>\n","      <th>author</th>\n","      <th>license</th>\n","      <th>rating</th>\n","      <th>time</th>\n","      <th>url</th>\n","      <th>filename</th>\n","      <th>new_target</th>\n","      <th>len_new_target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>afrsil1</td>\n","      <td>[]</td>\n","      <td>['call', 'flight call']</td>\n","      <td>12.3910</td>\n","      <td>-1.4930</td>\n","      <td>Euodice cantans</td>\n","      <td>African Silverbill</td>\n","      <td>Bram Piot</td>\n","      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n","      <td>2.5</td>\n","      <td>08:00</td>\n","      <td>https://www.xeno-canto.org/125458</td>\n","      <td>afrsil1/XC125458.ogg</td>\n","      <td>afrsil1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>afrsil1</td>\n","      <td>['houspa', 'redava', 'zebdov']</td>\n","      <td>['call']</td>\n","      <td>19.8801</td>\n","      <td>-155.7254</td>\n","      <td>Euodice cantans</td>\n","      <td>African Silverbill</td>\n","      <td>Dan Lane</td>\n","      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n","      <td>3.5</td>\n","      <td>08:30</td>\n","      <td>https://www.xeno-canto.org/175522</td>\n","      <td>afrsil1/XC175522.ogg</td>\n","      <td>afrsil1 houspa redava zebdov</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>afrsil1</td>\n","      <td>[]</td>\n","      <td>['call', 'song']</td>\n","      <td>16.2901</td>\n","      <td>-16.0321</td>\n","      <td>Euodice cantans</td>\n","      <td>African Silverbill</td>\n","      <td>Bram Piot</td>\n","      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n","      <td>4.0</td>\n","      <td>11:30</td>\n","      <td>https://www.xeno-canto.org/177993</td>\n","      <td>afrsil1/XC177993.ogg</td>\n","      <td>afrsil1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>afrsil1</td>\n","      <td>[]</td>\n","      <td>['alarm call', 'call']</td>\n","      <td>17.0922</td>\n","      <td>54.2958</td>\n","      <td>Euodice cantans</td>\n","      <td>African Silverbill</td>\n","      <td>Oscar Campbell</td>\n","      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n","      <td>4.0</td>\n","      <td>11:00</td>\n","      <td>https://www.xeno-canto.org/205893</td>\n","      <td>afrsil1/XC205893.ogg</td>\n","      <td>afrsil1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>afrsil1</td>\n","      <td>[]</td>\n","      <td>['flight call']</td>\n","      <td>21.4581</td>\n","      <td>-157.7252</td>\n","      <td>Euodice cantans</td>\n","      <td>African Silverbill</td>\n","      <td>Ross Gallardy</td>\n","      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n","      <td>3.0</td>\n","      <td>16:30</td>\n","      <td>https://www.xeno-canto.org/207431</td>\n","      <td>afrsil1/XC207431.ogg</td>\n","      <td>afrsil1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  primary_label                secondary_labels                     type  \\\n","0       afrsil1                              []  ['call', 'flight call']   \n","1       afrsil1  ['houspa', 'redava', 'zebdov']                 ['call']   \n","2       afrsil1                              []         ['call', 'song']   \n","3       afrsil1                              []   ['alarm call', 'call']   \n","4       afrsil1                              []          ['flight call']   \n","\n","   latitude  longitude  scientific_name         common_name          author  \\\n","0   12.3910    -1.4930  Euodice cantans  African Silverbill       Bram Piot   \n","1   19.8801  -155.7254  Euodice cantans  African Silverbill        Dan Lane   \n","2   16.2901   -16.0321  Euodice cantans  African Silverbill       Bram Piot   \n","3   17.0922    54.2958  Euodice cantans  African Silverbill  Oscar Campbell   \n","4   21.4581  -157.7252  Euodice cantans  African Silverbill   Ross Gallardy   \n","\n","                                             license  rating   time  \\\n","0  Creative Commons Attribution-NonCommercial-Sha...     2.5  08:00   \n","1  Creative Commons Attribution-NonCommercial-Sha...     3.5  08:30   \n","2  Creative Commons Attribution-NonCommercial-Sha...     4.0  11:30   \n","3  Creative Commons Attribution-NonCommercial-Sha...     4.0  11:00   \n","4  Creative Commons Attribution-NonCommercial-Sha...     3.0  16:30   \n","\n","                                 url              filename  \\\n","0  https://www.xeno-canto.org/125458  afrsil1/XC125458.ogg   \n","1  https://www.xeno-canto.org/175522  afrsil1/XC175522.ogg   \n","2  https://www.xeno-canto.org/177993  afrsil1/XC177993.ogg   \n","3  https://www.xeno-canto.org/205893  afrsil1/XC205893.ogg   \n","4  https://www.xeno-canto.org/207431  afrsil1/XC207431.ogg   \n","\n","                     new_target  len_new_target  \n","0                      afrsil1                1  \n","1  afrsil1 houspa redava zebdov               4  \n","2                      afrsil1                1  \n","3                      afrsil1                1  \n","4                      afrsil1                1  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.read_csv('input/birdclef-2022/train_metadata.csv')  #Changed filepath to suit\n","\n","train['new_target'] = train['primary_label'] + ' ' + train['secondary_labels'].map(lambda x: ' '.join(ast.literal_eval(x)))\n","train['len_new_target'] = train['new_target'].map(lambda x: len(x.split()))\n","# train['len_new_target'].value_counts()\n","train.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file_path</th>\n","      <th>filename</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>input/train_np_1/bcnher/XC256938.ogg.npy</td>\n","      <td>bcnher/XC256938.ogg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>input/train_np_1/bcnher/XC648367.ogg.npy</td>\n","      <td>bcnher/XC648367.ogg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>input/train_np_1/bcnher/XC587839.ogg.npy</td>\n","      <td>bcnher/XC587839.ogg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>input/train_np_1/bcnher/XC548602.ogg.npy</td>\n","      <td>bcnher/XC548602.ogg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>input/train_np_1/bcnher/XC500284.ogg.npy</td>\n","      <td>bcnher/XC500284.ogg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                  file_path             filename\n","0  input/train_np_1/bcnher/XC256938.ogg.npy  bcnher/XC256938.ogg\n","1  input/train_np_1/bcnher/XC648367.ogg.npy  bcnher/XC648367.ogg\n","2  input/train_np_1/bcnher/XC587839.ogg.npy  bcnher/XC587839.ogg\n","3  input/train_np_1/bcnher/XC548602.ogg.npy  bcnher/XC548602.ogg\n","4  input/train_np_1/bcnher/XC500284.ogg.npy  bcnher/XC500284.ogg"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["path_df = pd.DataFrame(all_path, columns=['file_path'])\n","path_df['filename'] = path_df['file_path'].map(lambda x: x.split('/')[-2]+'/'+x.split('/')[-1][:-4])\n","path_df.head()"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(14852, 16)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>primary_label</th>\n","      <th>secondary_labels</th>\n","      <th>type</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>scientific_name</th>\n","      <th>common_name</th>\n","      <th>author</th>\n","      <th>license</th>\n","      <th>rating</th>\n","      <th>time</th>\n","      <th>url</th>\n","      <th>filename</th>\n","      <th>new_target</th>\n","      <th>len_new_target</th>\n","      <th>file_path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>afrsil1</td>\n","      <td>[]</td>\n","      <td>['call', 'flight call']</td>\n","      <td>12.3910</td>\n","      <td>-1.4930</td>\n","      <td>Euodice cantans</td>\n","      <td>African Silverbill</td>\n","      <td>Bram Piot</td>\n","      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n","      <td>2.5</td>\n","      <td>08:00</td>\n","      <td>https://www.xeno-canto.org/125458</td>\n","      <td>afrsil1/XC125458.ogg</td>\n","      <td>afrsil1</td>\n","      <td>1</td>\n","      <td>input/train_np_1/afrsil1/XC125458.ogg.npy</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>afrsil1</td>\n","      <td>['houspa', 'redava', 'zebdov']</td>\n","      <td>['call']</td>\n","      <td>19.8801</td>\n","      <td>-155.7254</td>\n","      <td>Euodice cantans</td>\n","      <td>African Silverbill</td>\n","      <td>Dan Lane</td>\n","      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n","      <td>3.5</td>\n","      <td>08:30</td>\n","      <td>https://www.xeno-canto.org/175522</td>\n","      <td>afrsil1/XC175522.ogg</td>\n","      <td>afrsil1 houspa redava zebdov</td>\n","      <td>4</td>\n","      <td>input/train_np_1/afrsil1/XC175522.ogg.npy</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>afrsil1</td>\n","      <td>[]</td>\n","      <td>['call', 'song']</td>\n","      <td>16.2901</td>\n","      <td>-16.0321</td>\n","      <td>Euodice cantans</td>\n","      <td>African Silverbill</td>\n","      <td>Bram Piot</td>\n","      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n","      <td>4.0</td>\n","      <td>11:30</td>\n","      <td>https://www.xeno-canto.org/177993</td>\n","      <td>afrsil1/XC177993.ogg</td>\n","      <td>afrsil1</td>\n","      <td>1</td>\n","      <td>input/train_np_1/afrsil1/XC177993.ogg.npy</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>afrsil1</td>\n","      <td>[]</td>\n","      <td>['alarm call', 'call']</td>\n","      <td>17.0922</td>\n","      <td>54.2958</td>\n","      <td>Euodice cantans</td>\n","      <td>African Silverbill</td>\n","      <td>Oscar Campbell</td>\n","      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n","      <td>4.0</td>\n","      <td>11:00</td>\n","      <td>https://www.xeno-canto.org/205893</td>\n","      <td>afrsil1/XC205893.ogg</td>\n","      <td>afrsil1</td>\n","      <td>1</td>\n","      <td>input/train_np_1/afrsil1/XC205893.ogg.npy</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>afrsil1</td>\n","      <td>[]</td>\n","      <td>['flight call']</td>\n","      <td>21.4581</td>\n","      <td>-157.7252</td>\n","      <td>Euodice cantans</td>\n","      <td>African Silverbill</td>\n","      <td>Ross Gallardy</td>\n","      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n","      <td>3.0</td>\n","      <td>16:30</td>\n","      <td>https://www.xeno-canto.org/207431</td>\n","      <td>afrsil1/XC207431.ogg</td>\n","      <td>afrsil1</td>\n","      <td>1</td>\n","      <td>input/train_np_1/afrsil1/XC207431.ogg.npy</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  primary_label                secondary_labels                     type  \\\n","0       afrsil1                              []  ['call', 'flight call']   \n","1       afrsil1  ['houspa', 'redava', 'zebdov']                 ['call']   \n","2       afrsil1                              []         ['call', 'song']   \n","3       afrsil1                              []   ['alarm call', 'call']   \n","4       afrsil1                              []          ['flight call']   \n","\n","   latitude  longitude  scientific_name         common_name          author  \\\n","0   12.3910    -1.4930  Euodice cantans  African Silverbill       Bram Piot   \n","1   19.8801  -155.7254  Euodice cantans  African Silverbill        Dan Lane   \n","2   16.2901   -16.0321  Euodice cantans  African Silverbill       Bram Piot   \n","3   17.0922    54.2958  Euodice cantans  African Silverbill  Oscar Campbell   \n","4   21.4581  -157.7252  Euodice cantans  African Silverbill   Ross Gallardy   \n","\n","                                             license  rating   time  \\\n","0  Creative Commons Attribution-NonCommercial-Sha...     2.5  08:00   \n","1  Creative Commons Attribution-NonCommercial-Sha...     3.5  08:30   \n","2  Creative Commons Attribution-NonCommercial-Sha...     4.0  11:30   \n","3  Creative Commons Attribution-NonCommercial-Sha...     4.0  11:00   \n","4  Creative Commons Attribution-NonCommercial-Sha...     3.0  16:30   \n","\n","                                 url              filename  \\\n","0  https://www.xeno-canto.org/125458  afrsil1/XC125458.ogg   \n","1  https://www.xeno-canto.org/175522  afrsil1/XC175522.ogg   \n","2  https://www.xeno-canto.org/177993  afrsil1/XC177993.ogg   \n","3  https://www.xeno-canto.org/205893  afrsil1/XC205893.ogg   \n","4  https://www.xeno-canto.org/207431  afrsil1/XC207431.ogg   \n","\n","                     new_target  len_new_target  \\\n","0                      afrsil1                1   \n","1  afrsil1 houspa redava zebdov               4   \n","2                      afrsil1                1   \n","3                      afrsil1                1   \n","4                      afrsil1                1   \n","\n","                                   file_path  \n","0  input/train_np_1/afrsil1/XC125458.ogg.npy  \n","1  input/train_np_1/afrsil1/XC175522.ogg.npy  \n","2  input/train_np_1/afrsil1/XC177993.ogg.npy  \n","3  input/train_np_1/afrsil1/XC205893.ogg.npy  \n","4  input/train_np_1/afrsil1/XC207431.ogg.npy  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.merge(train, path_df, on='filename')\n","print(train.shape)\n","train.head()"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/olly/miniconda3/envs/AudioML_3060/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  warnings.warn(\n"]}],"source":["Fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","for n, (trn_index, val_index) in enumerate(Fold.split(train, train['primary_label'])):\n","    train.loc[val_index, 'kfold'] = int(n)\n","train['kfold'] = train['kfold'].astype(int)"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["train.to_csv('train_folds.csv', index=False)"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["class CFG:\n","    ######################\n","    # Globals #\n","    ######################\n","    EXP_ID = 'EX005'\n","    seed = 71\n","    epochs = 23\n","    cutmix_and_mixup_epochs = 18\n","    folds =  [0, 1, 2, 3, 4]  #[0]\n","    N_FOLDS = 5\n","    LR = 1e-3\n","    ETA_MIN = 1e-6\n","    WEIGHT_DECAY = 1e-6\n","    train_bs = 16 # 32\n","    valid_bs = 32 # 64\n","    base_model_name = \"tf_efficientnet_b0_ns\"\n","    EARLY_STOPPING = True\n","    DEBUG = False # True\n","    EVALUATION = 'AUC'\n","    apex = True\n","\n","    pooling = \"max\"\n","    pretrained = True\n","    num_classes = 152\n","    in_channels = 3\n","    target_columns = 'afrsil1 akekee akepa1 akiapo akikik amewig aniani apapan arcter \\\n","                      barpet bcnher belkin1 bkbplo bknsti bkwpet blkfra blknod bongul \\\n","                      brant brnboo brnnod brnowl brtcur bubsan buffle bulpet burpar buwtea \\\n","                      cacgoo1 calqua cangoo canvas caster1 categr chbsan chemun chukar cintea \\\n","                      comgal1 commyn compea comsan comwax coopet crehon dunlin elepai ercfra eurwig \\\n","                      fragul gadwal gamqua glwgul gnwtea golphe grbher3 grefri gresca gryfra gwfgoo \\\n","                      hawama hawcoo hawcre hawgoo hawhaw hawpet1 hoomer houfin houspa hudgod iiwi incter1 \\\n","                      jabwar japqua kalphe kauama laugul layalb lcspet leasan leater1 lessca lesyel lobdow lotjae \\\n","                      madpet magpet1 mallar3 masboo mauala maupar merlin mitpar moudov norcar norhar2 normoc norpin \\\n","                      norsho nutman oahama omao osprey pagplo palila parjae pecsan peflov perfal pibgre pomjae puaioh \\\n","                      reccar redava redjun redpha1 refboo rempar rettro ribgul rinduc rinphe rocpig rorpar rudtur ruff \\\n","                      saffin sander semplo sheowl shtsan skylar snogoo sooshe sooter1 sopsku1 sora spodov sposan \\\n","                      towsol wantat1 warwhe1 wesmea wessan wetshe whfibi whiter whttro wiltur yebcar yefcan zebdov'.split()\n","\n","    img_size = 224 #224 # 128\n","    main_metric = \"epoch_f1_at_03\"\n","\n","    period = 5\n","    n_mels = 224 #224 # 128\n","    fmin = 20\n","    fmax = 16000\n","    n_fft = 2048\n","    hop_length = 512\n","    sample_rate = 32000\n","    melspectrogram_parameters = {\n","        \"n_mels\": 224, #224, # 128,\n","        \"fmin\": 20,\n","        \"fmax\": 16000\n","    }\n","    \n","    \n","class AudioParams:\n","    \"\"\"\n","    Parameters used for the audio data\n","    \"\"\"\n","    sr = CFG.sample_rate\n","    duration = CFG.period\n","    # Melspectrogram\n","    n_mels = CFG.n_mels\n","    fmin = CFG.fmin\n","    fmax = CFG.fmax"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["class Compose:\n","    def __init__(self, transforms: list):\n","        self.transforms = transforms\n","\n","    def __call__(self, y: np.ndarray, sr):\n","        for trns in self.transforms:\n","            y = trns(y, sr)\n","        return y\n","\n","\n","class AudioTransform:\n","    def __init__(self, always_apply=False, p=0.5):\n","        self.always_apply = always_apply\n","        self.p = p\n","\n","    def __call__(self, y: np.ndarray, sr):\n","        if self.always_apply:\n","            return self.apply(y, sr=sr)\n","        else:\n","            if np.random.rand() < self.p:\n","                return self.apply(y, sr=sr)\n","            else:\n","                return y\n","\n","    def apply(self, y: np.ndarray, **params):\n","        raise NotImplementedError\n","\n","\n","class OneOf(Compose):\n","    # https://github.com/albumentations-team/albumentations/blob/master/albumentations/core/composition.py\n","    def __init__(self, transforms, p=0.5):\n","        super().__init__(transforms)\n","        self.p = p\n","        transforms_ps = [t.p for t in transforms]\n","        s = sum(transforms_ps)\n","        self.transforms_ps = [t / s for t in transforms_ps]\n","\n","    def __call__(self, y: np.ndarray, sr):\n","        data = y\n","        if self.transforms_ps and (random.random() < self.p):\n","            random_state = np.random.RandomState(random.randint(0, 2 ** 32 - 1))\n","            t = random_state.choice(self.transforms, p=self.transforms_ps)\n","            data = t(y, sr)\n","        return data\n","\n","\n","class Normalize(AudioTransform):\n","    def __init__(self, always_apply=False, p=1):\n","        super().__init__(always_apply, p)\n","\n","    def apply(self, y: np.ndarray, **params):\n","        max_vol = np.abs(y).max()\n","        y_vol = y * 1 / max_vol\n","        return np.asfortranarray(y_vol)\n","\n","\n","class NewNormalize(AudioTransform):\n","    def __init__(self, always_apply=False, p=1):\n","        super().__init__(always_apply, p)\n","\n","    def apply(self, y: np.ndarray, **params):\n","        y_mm = y - y.mean()\n","        return y_mm / y_mm.abs().max()\n","\n","\n","class NoiseInjection(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, max_noise_level=0.5):\n","        super().__init__(always_apply, p)\n","\n","        self.noise_level = (0.0, max_noise_level)\n","\n","    def apply(self, y: np.ndarray, **params):\n","        noise_level = np.random.uniform(*self.noise_level)\n","        noise = np.random.randn(len(y))\n","        augmented = (y + noise * noise_level).astype(y.dtype)\n","        return augmented\n","\n","\n","class GaussianNoise(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, min_snr=5, max_snr=20):\n","        super().__init__(always_apply, p)\n","\n","        self.min_snr = min_snr\n","        self.max_snr = max_snr\n","\n","    def apply(self, y: np.ndarray, **params):\n","        snr = np.random.uniform(self.min_snr, self.max_snr)\n","        a_signal = np.sqrt(y ** 2).max()\n","        a_noise = a_signal / (10 ** (snr / 20))\n","\n","        white_noise = np.random.randn(len(y))\n","        a_white = np.sqrt(white_noise ** 2).max()\n","        augmented = (y + white_noise * 1 / a_white * a_noise).astype(y.dtype)\n","        return augmented\n","\n","\n","class PinkNoise(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, min_snr=5, max_snr=20):\n","        super().__init__(always_apply, p)\n","\n","        self.min_snr = min_snr\n","        self.max_snr = max_snr\n","\n","    def apply(self, y: np.ndarray, **params):\n","        snr = np.random.uniform(self.min_snr, self.max_snr)\n","        a_signal = np.sqrt(y ** 2).max()\n","        a_noise = a_signal / (10 ** (snr / 20))\n","\n","        pink_noise = cn.powerlaw_psd_gaussian(1, len(y))\n","        a_pink = np.sqrt(pink_noise ** 2).max()\n","        augmented = (y + pink_noise * 1 / a_pink * a_noise).astype(y.dtype)\n","        return augmented\n","\n","\n","class PitchShift(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, max_range=5):\n","        super().__init__(always_apply, p)\n","        self.max_range = max_range\n","\n","    def apply(self, y: np.ndarray, sr, **params):\n","        n_steps = np.random.randint(-self.max_range, self.max_range)\n","        augmented = librosa.effects.pitch_shift(y, sr, n_steps)\n","        return augmented\n","\n","\n","class TimeStretch(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, max_rate=1):\n","        super().__init__(always_apply, p)\n","        self.max_rate = max_rate\n","\n","    def apply(self, y: np.ndarray, **params):\n","        rate = np.random.uniform(0, self.max_rate)\n","        augmented = librosa.effects.time_stretch(y, rate)\n","        return augmented\n","\n","\n","def _db2float(db: float, amplitude=True):\n","    if amplitude:\n","        return 10 ** (db / 20)\n","    else:\n","        return 10 ** (db / 10)\n","\n","\n","def volume_down(y: np.ndarray, db: float):\n","    \"\"\"\n","    Low level API for decreasing the volume\n","    Parameters\n","    ----------\n","    y: numpy.ndarray\n","        stereo / monaural input audio\n","    db: float\n","        how much decibel to decrease\n","    Returns\n","    -------\n","    applied: numpy.ndarray\n","        audio with decreased volume\n","    \"\"\"\n","    applied = y * _db2float(-db)\n","    return applied\n","\n","\n","def volume_up(y: np.ndarray, db: float):\n","    \"\"\"\n","    Low level API for increasing the volume\n","    Parameters\n","    ----------\n","    y: numpy.ndarray\n","        stereo / monaural input audio\n","    db: float\n","        how much decibel to increase\n","    Returns\n","    -------\n","    applied: numpy.ndarray\n","        audio with increased volume\n","    \"\"\"\n","    applied = y * _db2float(db)\n","    return applied\n","\n","\n","class RandomVolume(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, limit=10):\n","        super().__init__(always_apply, p)\n","        self.limit = limit\n","\n","    def apply(self, y: np.ndarray, **params):\n","        db = np.random.uniform(-self.limit, self.limit)\n","        if db >= 0:\n","            return volume_up(y, db)\n","        else:\n","            return volume_down(y, db)\n","\n","\n","class CosineVolume(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, limit=10):\n","        super().__init__(always_apply, p)\n","        self.limit = limit\n","\n","    def apply(self, y: np.ndarray, **params):\n","        db = np.random.uniform(-self.limit, self.limit)\n","        cosine = np.cos(np.arange(len(y)) / len(y) * np.pi * 2)\n","        dbs = _db2float(cosine * db)\n","        return y * dbs"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[],"source":["OUTPUT_DIR = f'output'    #was ./ for Kaggle\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)\n","   \n","    \n","def set_seed(seed=42):\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    \n","set_seed(CFG.seed)"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["def calc_loss(y_true, y_pred):\n","    return metrics.roc_auc_score(np.array(y_true), np.array(y_pred))\n","\n","\n","# ====================================================\n","# Training helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","        \n","\n","class MetricMeter(object):\n","    def __init__(self):\n","        self.reset()\n","    \n","    def reset(self):\n","        self.y_true = []\n","        self.y_pred = []\n","    \n","    def update(self, y_true, y_pred):\n","        self.y_true.extend(y_true.cpu().detach().numpy().tolist())\n","        self.y_pred.extend(y_pred[\"clipwise_output\"].cpu().detach().numpy().tolist())\n","\n","    @property\n","    def avg(self):\n","        self.f1_03 = metrics.f1_score(np.array(self.y_true), np.array(self.y_pred) > 0.3, average=\"micro\")\n","        self.f1_05 = metrics.f1_score(np.array(self.y_true), np.array(self.y_pred) > 0.5, average=\"micro\")\n","        \n","        return {\n","            \"f1_at_03\" : self.f1_03,\n","            \"f1_at_05\" : self.f1_05,\n","        }\n","    \n","    \n","# https://www.kaggle.com/c/rfcx-species-audio-detection/discussion/213075\n","class BCEFocalLoss(nn.Module):\n","    def __init__(self, alpha=0.25, gamma=2.0):\n","        super().__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","\n","    def forward(self, preds, targets):\n","        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(preds, targets)\n","        probas = torch.sigmoid(preds)\n","        loss = targets * self.alpha * \\\n","            (1. - probas)**self.gamma * bce_loss + \\\n","            (1. - targets) * probas**self.gamma * bce_loss\n","        loss = loss.mean()\n","        return loss\n","\n","\n","class BCEFocal2WayLoss(nn.Module):\n","    def __init__(self, weights=[1, 1], class_weights=None):\n","        super().__init__()\n","\n","        self.focal = BCEFocalLoss()\n","\n","        self.weights = weights\n","\n","    def forward(self, input, target):\n","        input_ = input[\"logit\"]\n","        target = target.float()\n","\n","        framewise_output = input[\"framewise_logit\"]\n","        clipwise_output_with_max, _ = framewise_output.max(dim=1)\n","\n","        loss = self.focal(input_, target)\n","        aux_loss = self.focal(clipwise_output_with_max, target)\n","\n","        return self.weights[0] * loss + self.weights[1] * aux_loss"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/olly/miniconda3/envs/AudioML_3060/lib/python3.9/site-packages/albumentations/augmentations/transforms.py:689: FutureWarning: This class has been deprecated. Please use CoarseDropout\n","  warnings.warn(\n"]}],"source":["def compute_melspec(y, params):\n","    \"\"\"\n","    Computes a mel-spectrogram and puts it at decibel scale\n","    Arguments:\n","        y {np array} -- signal\n","        params {AudioParams} -- Parameters to use for the spectrogram. Expected to have the attributes sr, n_mels, f_min, f_max\n","    Returns:\n","        np array -- Mel-spectrogram\n","    \"\"\"\n","    melspec = librosa.feature.melspectrogram(\n","        y=y, sr=params.sr, n_mels=params.n_mels, fmin=params.fmin, fmax=params.fmax,\n","    )\n","\n","    melspec = librosa.power_to_db(melspec).astype(np.float32)\n","    return melspec\n","\n","\n","def crop_or_pad(y, length, sr, train=True, probs=None):\n","    \"\"\"\n","    Crops an array to a chosen length\n","    Arguments:\n","        y {1D np array} -- Array to crop\n","        length {int} -- Length of the crop\n","        sr {int} -- Sampling rate\n","    Keyword Arguments:\n","        train {bool} -- Whether we are at train time. If so, crop randomly, else return the beginning of y (default: {True})\n","        probs {None or numpy array} -- Probabilities to use to chose where to crop (default: {None})\n","    Returns:\n","        1D np array -- Cropped array\n","    \"\"\"\n","    if len(y) <= length:\n","        y = np.concatenate([y, np.zeros(length - len(y))])\n","    else:\n","        if not train:\n","            start = 0\n","        elif probs is None:\n","            start = np.random.randint(len(y) - length)\n","        else:\n","            start = (\n","                    np.random.choice(np.arange(len(probs)), p=probs) + np.random.random()\n","            )\n","            start = int(sr * (start))\n","\n","        y = y[start: start + length]\n","\n","    return y.astype(np.float32)\n","\n","\n","def mono_to_color(X, eps=1e-6, mean=None, std=None):\n","    \"\"\"\n","    Converts a one channel array to a 3 channel one in [0, 255]\n","    Arguments:\n","        X {numpy array [H x W]} -- 2D array to convert\n","    Keyword Arguments:\n","        eps {float} -- To avoid dividing by 0 (default: {1e-6})\n","        mean {None or np array} -- Mean for normalization (default: {None})\n","        std {None or np array} -- Std for normalization (default: {None})\n","    Returns:\n","        numpy array [3 x H x W] -- RGB numpy array\n","    \"\"\"\n","    X = np.stack([X, X, X], axis=-1)\n","\n","    # Standardize\n","    mean = mean or X.mean()\n","    std = std or X.std()\n","    X = (X - mean) / (std + eps)\n","\n","    # Normalize to [0, 255]\n","    _min, _max = X.min(), X.max()\n","\n","    if (_max - _min) > eps:\n","        V = np.clip(X, _min, _max)\n","        V = 255 * (V - _min) / (_max - _min)\n","        V = V.astype(np.uint8)\n","    else:\n","        V = np.zeros_like(X, dtype=np.uint8)\n","\n","    return V\n","\n","\n","mean = (0.485, 0.456, 0.406) # RGB\n","std = (0.229, 0.224, 0.225) # RGB\n","\n","albu_transforms = {\n","    'train' : A.Compose([\n","            A.HorizontalFlip(p=0.5),\n","            A.OneOf([\n","                A.Cutout(max_h_size=5, max_w_size=16),\n","                A.CoarseDropout(max_holes=4),\n","            ], p=0.5),\n","            A.Normalize(mean, std),\n","    ]),\n","    'valid' : A.Compose([\n","            A.Normalize(mean, std),\n","    ]),\n","}\n","\n","\n","class WaveformDataset(torch.utils.data.Dataset):\n","    def __init__(self,\n","                 df: pd.DataFrame,\n","                 mode='train'):\n","        self.df = df\n","        self.mode = mode\n","\n","        if mode == 'train':\n","            self.wave_transforms = Compose(\n","                [\n","                    OneOf(\n","                        [\n","                            NoiseInjection(p=1, max_noise_level=0.04),\n","                            GaussianNoise(p=1, min_snr=5, max_snr=20),\n","                            PinkNoise(p=1, min_snr=5, max_snr=20),\n","                        ],\n","                        p=0.2,\n","                    ),\n","                    RandomVolume(p=0.2, limit=4),\n","                    Normalize(p=1),\n","                ]\n","            )\n","        else:\n","            self.wave_transforms = Compose(\n","                [\n","                    Normalize(p=1),\n","                ]\n","            )\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx: int):\n","        SR = 32000\n","        sample = self.df.loc[idx, :]\n","        \n","        wav_path = sample[\"file_path\"]\n","        labels = sample[\"new_target\"]\n","\n","        y = np.load(wav_path)\n","\n","        # SEC = int(len(y)/2/SR)\n","        # if SEC > 0:\n","        #     start = np.random.randint(SEC)\n","        #     end = start+AudioParams.duration\n","        if len(y) > 0:\n","            y = y[:AudioParams.duration*SR]\n","\n","            if self.wave_transforms:\n","                y = self.wave_transforms(y, sr=SR)\n","\n","        y = np.concatenate([y, y, y])[:AudioParams.duration * AudioParams.sr] \n","        y = crop_or_pad(y, AudioParams.duration * AudioParams.sr, sr=AudioParams.sr, train=True, probs=None)\n","        image = compute_melspec(y, AudioParams)\n","        image = mono_to_color(image)\n","        image = image.astype(np.uint8)\n","        \n","        # image = np.load(wav_path) # (224, 313, 3)\n","        image = albu_transforms[self.mode](image=image)['image']\n","        image = image.T\n","        \n","        targets = np.zeros(len(CFG.target_columns), dtype=float)\n","        for ebird_code in labels.split():\n","            targets[CFG.target_columns.index(ebird_code)] = 1.0\n","\n","        return {\n","            \"image\": image,\n","            \"targets\": targets,\n","        }"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[],"source":["def init_layer(layer):\n","    nn.init.xavier_uniform_(layer.weight)\n","\n","    if hasattr(layer, \"bias\"):\n","        if layer.bias is not None:\n","            layer.bias.data.fill_(0.)\n","\n","\n","def init_bn(bn):\n","    bn.bias.data.fill_(0.)\n","    bn.weight.data.fill_(1.0)\n","\n","\n","def init_weights(model):\n","    classname = model.__class__.__name__\n","    if classname.find(\"Conv2d\") != -1:\n","        nn.init.xavier_uniform_(model.weight, gain=np.sqrt(2))\n","        model.bias.data.fill_(0)\n","    elif classname.find(\"BatchNorm\") != -1:\n","        model.weight.data.normal_(1.0, 0.02)\n","        model.bias.data.fill_(0)\n","    elif classname.find(\"GRU\") != -1:\n","        for weight in model.parameters():\n","            if len(weight.size()) > 1:\n","                nn.init.orghogonal_(weight.data)\n","    elif classname.find(\"Linear\") != -1:\n","        model.weight.data.normal_(0, 0.01)\n","        model.bias.data.zero_()\n","\n","\n","def interpolate(x: torch.Tensor, ratio: int):\n","    \"\"\"Interpolate data in time domain. This is used to compensate the\n","    resolution reduction in downsampling of a CNN.\n","    Args:\n","      x: (batch_size, time_steps, classes_num)\n","      ratio: int, ratio to interpolate\n","    Returns:\n","      upsampled: (batch_size, time_steps * ratio, classes_num)\n","    \"\"\"\n","    (batch_size, time_steps, classes_num) = x.shape\n","    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n","    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n","    return upsampled\n","\n","\n","def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n","    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n","    is the same as the value of the last frame.\n","    Args:\n","      framewise_output: (batch_size, frames_num, classes_num)\n","      frames_num: int, number of frames to pad\n","    Outputs:\n","      output: (batch_size, frames_num, classes_num)\n","    \"\"\"\n","    output = F.interpolate(\n","        framewise_output.unsqueeze(1),\n","        size=(frames_num, framewise_output.size(2)),\n","        align_corners=True,\n","        mode=\"bilinear\").squeeze(1)\n","\n","    return output\n","\n","\n","class AttBlockV2(nn.Module):\n","    def __init__(self,\n","                 in_features: int,\n","                 out_features: int,\n","                 activation=\"linear\"):\n","        super().__init__()\n","\n","        self.activation = activation\n","        self.att = nn.Conv1d(\n","            in_channels=in_features,\n","            out_channels=out_features,\n","            kernel_size=1,\n","            stride=1,\n","            padding=0,\n","            bias=True)\n","        self.cla = nn.Conv1d(\n","            in_channels=in_features,\n","            out_channels=out_features,\n","            kernel_size=1,\n","            stride=1,\n","            padding=0,\n","            bias=True)\n","\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        init_layer(self.att)\n","        init_layer(self.cla)\n","\n","    def forward(self, x):\n","        # x: (n_samples, n_in, n_time)\n","        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n","        cla = self.nonlinear_transform(self.cla(x))\n","        x = torch.sum(norm_att * cla, dim=2)\n","        return x, norm_att, cla\n","\n","    def nonlinear_transform(self, x):\n","        if self.activation == 'linear':\n","            return x\n","        elif self.activation == 'sigmoid':\n","            return torch.sigmoid(x)\n","\n","\n","class TimmSED(nn.Module):\n","    def __init__(self, base_model_name: str, pretrained=False, num_classes=24, in_channels=1):\n","        super().__init__()\n","\n","        self.spec_augmenter = SpecAugmentation(time_drop_width=64//2, time_stripes_num=2,\n","                                               freq_drop_width=8//2, freq_stripes_num=2)\n","\n","        self.bn0 = nn.BatchNorm2d(CFG.n_mels)\n","\n","        base_model = timm.create_model(\n","            base_model_name, pretrained=pretrained, in_chans=in_channels)\n","        layers = list(base_model.children())[:-2]\n","        self.encoder = nn.Sequential(*layers)\n","\n","        if hasattr(base_model, \"fc\"):\n","            in_features = base_model.fc.in_features\n","        else:\n","            in_features = base_model.classifier.in_features\n","\n","        self.fc1 = nn.Linear(in_features, in_features, bias=True)\n","        self.att_block = AttBlockV2(\n","            in_features, num_classes, activation=\"sigmoid\")\n","\n","        self.init_weight()\n","\n","    def init_weight(self):\n","        init_bn(self.bn0)\n","        init_layer(self.fc1)\n","        \n","\n","    def forward(self, input_data):\n","        x = input_data # (batch_size, 3, time_steps, mel_bins)\n","\n","        frames_num = x.shape[2]\n","\n","        x = x.transpose(1, 3)\n","        x = self.bn0(x)\n","        x = x.transpose(1, 3)\n","\n","        if self.training:\n","            if random.random() < 0.25:\n","                x = self.spec_augmenter(x)\n","\n","        x = x.transpose(2, 3)\n","\n","        x = self.encoder(x)\n","        \n","        # Aggregate in frequency axis\n","        x = torch.mean(x, dim=3)\n","\n","        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n","        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n","        x = x1 + x2\n","\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = x.transpose(1, 2)\n","        x = F.relu_(self.fc1(x))\n","        x = x.transpose(1, 2)\n","        x = F.dropout(x, p=0.5, training=self.training)\n","\n","        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n","        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n","        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n","        segmentwise_output = segmentwise_output.transpose(1, 2)\n","\n","        interpolate_ratio = frames_num // segmentwise_output.size(1)\n","\n","        # Get framewise output\n","        framewise_output = interpolate(segmentwise_output,\n","                                       interpolate_ratio)\n","        framewise_output = pad_framewise_output(framewise_output, frames_num)\n","\n","        framewise_logit = interpolate(segmentwise_logit, interpolate_ratio)\n","        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n","\n","        output_dict = {\n","            'framewise_output': framewise_output,\n","            'clipwise_output': clipwise_output,\n","            'logit': logit,\n","            'framewise_logit': framewise_logit,\n","        }\n","\n","        return output_dict"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["def rand_bbox(size, lam):\n","    W = size[2]\n","    H = size[3]\n","    cut_rat = np.sqrt(1. - lam)\n","    cut_w = int(W * cut_rat)\n","    cut_h = int(H * cut_rat)\n","\n","    # uniform\n","    cx = np.random.randint(W)\n","    cy = np.random.randint(H)\n","\n","    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n","    bby1 = np.clip(cy - cut_h // 2, 0, H)\n","    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n","    bby2 = np.clip(cy + cut_h // 2, 0, H)\n","\n","    return bbx1, bby1, bbx2, bby2\n","\n","\n","def cutmix(data, targets, alpha):\n","    indices = torch.randperm(data.size(0))\n","    shuffled_data = data[indices]\n","    shuffled_targets = targets[indices]\n","\n","    lam = np.random.beta(alpha, alpha)\n","    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n","    data[:, :, bbx1:bbx2, bby1:bby2] = data[indices, :, bbx1:bbx2, bby1:bby2]\n","    # adjust lambda to exactly match pixel ratio\n","    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n","\n","    new_targets = [targets, shuffled_targets, lam]\n","    return data, new_targets\n","\n","def mixup(data, targets, alpha):\n","    indices = torch.randperm(data.size(0))\n","    shuffled_data = data[indices]\n","    shuffled_targets = targets[indices]\n","\n","    lam = np.random.beta(alpha, alpha)\n","    new_data = data * lam + shuffled_data * (1 - lam)\n","    new_targets = [targets, shuffled_targets, lam]\n","    return new_data, new_targets\n","\n","\n","def cutmix_criterion(preds, new_targets):\n","    targets1, targets2, lam = new_targets[0], new_targets[1], new_targets[2]\n","    criterion = BCEFocal2WayLoss()\n","    return lam * criterion(preds, targets1) + (1 - lam) * criterion(preds, targets2)\n","\n","def mixup_criterion(preds, new_targets):\n","    targets1, targets2, lam = new_targets[0], new_targets[1], new_targets[2]\n","    criterion = BCEFocal2WayLoss()\n","    return lam * criterion(preds, targets1) + (1 - lam) * criterion(preds, targets2)\n","\n","\n","def loss_fn(logits, targets):\n","    loss_fct = BCEFocal2WayLoss()\n","    loss = loss_fct(logits, targets)\n","    return loss"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[],"source":["def train_fn(model, data_loader, device, optimizer, scheduler):\n","    model.train()\n","    scaler = GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    scores = MetricMeter()\n","    tk0 = tqdm(data_loader, total=len(data_loader))\n","    \n","    for data in tk0:\n","        optimizer.zero_grad()\n","        inputs = data['image'].to(device)\n","        targets = data['targets'].to(device)\n","        with autocast(enabled=CFG.apex):\n","            outputs = model(inputs)\n","            loss = loss_fn(outputs, targets)\n","        \n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        \n","        scheduler.step()\n","        losses.update(loss.item(), inputs.size(0))\n","        scores.update(targets, outputs)\n","        tk0.set_postfix(loss=losses.avg)\n","    return scores.avg, losses.avg\n","\n","\n","def train_mixup_cutmix_fn(model, data_loader, device, optimizer, scheduler):\n","    model.train()\n","    scaler = GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    scores = MetricMeter()\n","    tk0 = tqdm(data_loader, total=len(data_loader))\n","\n","    for data in tk0:\n","        optimizer.zero_grad()\n","        inputs = data['image'].to(device)\n","        targets = data['targets'].to(device)\n","\n","        if np.random.rand()<0.5:\n","            inputs, new_targets = mixup(inputs, targets, 0.4)\n","            with autocast(enabled=CFG.apex):\n","                outputs = model(inputs)\n","                loss = mixup_criterion(outputs, new_targets) \n","        else:\n","            inputs, new_targets = cutmix(inputs, targets, 0.4)\n","            with autocast(enabled=CFG.apex):\n","                outputs = model(inputs)\n","                loss = cutmix_criterion(outputs, new_targets)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","        \n","        scheduler.step()\n","        losses.update(loss.item(), inputs.size(0))\n","        scores.update(new_targets[0], outputs)\n","        tk0.set_postfix(loss=losses.avg)\n","    return scores.avg, losses.avg\n","\n","\n","def valid_fn(model, data_loader, device):\n","    model.eval()\n","    losses = AverageMeter()\n","    scores = MetricMeter()\n","    tk0 = tqdm(data_loader, total=len(data_loader))\n","    valid_preds = []\n","    with torch.no_grad():\n","        for data in tk0:\n","            inputs = data['image'].to(device)\n","            targets = data['targets'].to(device)\n","            outputs = model(inputs)\n","            loss = loss_fn(outputs, targets)\n","            losses.update(loss.item(), inputs.size(0))\n","            scores.update(targets, outputs)\n","            tk0.set_postfix(loss=losses.avg)\n","    return scores.avg, losses.avg"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["def inference_fn(model, data_loader, device):\n","    model.eval()\n","    tk0 = tqdm(data_loader, total=len(data_loader))\n","    final_output = []\n","    final_target = []\n","    with torch.no_grad():\n","        for b_idx, data in enumerate(tk0):\n","            inputs = data['image'].to(device)\n","            targets = data['targets'].to(device).detach().cpu().numpy().tolist()\n","            output = model(inputs)\n","            output = output[\"clipwise_output\"].cpu().detach().cpu().numpy().tolist()\n","            final_output.extend(output)\n","            final_target.extend(targets)\n","    return final_output, final_target\n","\n","\n","def calc_cv(model_paths):\n","    df = pd.read_csv('train_folds.csv')\n","    y_true = []\n","    y_pred = []\n","    for fold, model_path in enumerate(model_paths):\n","        model = TimmSED(\n","            base_model_name=CFG.base_model_name,\n","            pretrained=CFG.pretrained,\n","            num_classes=CFG.num_classes,\n","            in_channels=CFG.in_channels)\n","\n","        model.to(device)\n","        model.load_state_dict(torch.load(model_path))\n","        model.eval()\n","\n","        val_df = df[df.kfold == fold].reset_index(drop=True)\n","        dataset = WaveformDataset(df=val_df, mode='valid')\n","        dataloader = torch.utils.data.DataLoader(\n","            dataset, batch_size=CFG.valid_bs, num_workers=0, pin_memory=True, shuffle=False\n","        )\n","\n","        final_output, final_target = inference_fn(model, dataloader, device)\n","        y_pred.extend(final_output)\n","        y_true.extend(final_target)\n","        torch.cuda.empty_cache()\n","\n","        f1_03 = metrics.f1_score(np.array(y_true), np.array(y_pred) > 0.3, average=\"micro\")\n","        print(f'micro f1_0.3 {f1_03}')\n","\n","    f1_03 = metrics.f1_score(np.array(y_true), np.array(y_pred) > 0.3, average=\"micro\")\n","    f1_05 = metrics.f1_score(np.array(y_true), np.array(y_pred) > 0.5, average=\"micro\")\n","\n","    print(f'overall micro f1_0.3 {f1_03}')\n","    print(f'overall micro f1_0.5 {f1_05}')\n","    return"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["====================================================================================================\n","Fold 0 Training\n","====================================================================================================\n"]},{"name":"stderr","output_type":"stream","text":["/home/olly/miniconda3/envs/AudioML_3060/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Starting 1 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [17:28<00:00,  1.41s/it, loss=0.0144]\n","100%|| 93/93 [01:14<00:00,  1.25it/s, loss=0.00801]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.01438  avg_val_loss: 0.00801  time: 1123s\n","Epoch 1 - train_f1_at_03:0.00424  valid_f1_at_03:0.00060\n","Epoch 1 - train_f1_at_05:0.00148  valid_f1_at_05:0.00000\n",">>>>>>>> Model Improved From -inf ----> 0.0006040471156750226\n","other scores here... 0.0006040471156750226, 0.0\n","Starting 2 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:55<00:00,  1.29s/it, loss=0.00845]\n","100%|| 93/93 [01:05<00:00,  1.43it/s, loss=0.00672]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.00845  avg_val_loss: 0.00672  time: 1021s\n","Epoch 2 - train_f1_at_03:0.01847  valid_f1_at_03:0.19333\n","Epoch 2 - train_f1_at_05:0.00045  valid_f1_at_05:0.04082\n",">>>>>>>> Model Improved From 0.0006040471156750226 ----> 0.19333333333333336\n","other scores here... 0.19333333333333336, 0.04081632653061225\n","Starting 3 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:13<00:00,  1.23s/it, loss=0.0077] \n","100%|| 93/93 [01:04<00:00,  1.44it/s, loss=0.0061] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.00770  avg_val_loss: 0.00610  time: 979s\n","Epoch 3 - train_f1_at_03:0.05794  valid_f1_at_03:0.31030\n","Epoch 3 - train_f1_at_05:0.00478  valid_f1_at_05:0.10297\n",">>>>>>>> Model Improved From 0.19333333333333336 ----> 0.3102968460111318\n","other scores here... 0.3102968460111318, 0.10297482837528606\n","Starting 4 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:58<00:00,  1.29s/it, loss=0.00709]\n","100%|| 93/93 [01:04<00:00,  1.43it/s, loss=0.00597]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.00709  avg_val_loss: 0.00597  time: 1024s\n","Epoch 4 - train_f1_at_03:0.10816  valid_f1_at_03:0.34799\n","Epoch 4 - train_f1_at_05:0.01013  valid_f1_at_05:0.14198\n",">>>>>>>> Model Improved From 0.3102968460111318 ----> 0.3479948253557568\n","other scores here... 0.3479948253557568, 0.14198218262806236\n","Starting 5 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:13<00:00,  1.23s/it, loss=0.00678]\n","100%|| 93/93 [01:04<00:00,  1.45it/s, loss=0.00494]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.00678  avg_val_loss: 0.00494  time: 979s\n","Epoch 5 - train_f1_at_03:0.14913  valid_f1_at_03:0.47040\n","Epoch 5 - train_f1_at_05:0.02168  valid_f1_at_05:0.25948\n",">>>>>>>> Model Improved From 0.3479948253557568 ----> 0.470397404703974\n","other scores here... 0.470397404703974, 0.2594820821344494\n","Starting 6 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:51<00:00,  1.28s/it, loss=0.00663]\n","100%|| 93/93 [01:04<00:00,  1.43it/s, loss=0.00456]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 - avg_train_loss: 0.00663  avg_val_loss: 0.00456  time: 1017s\n","Epoch 6 - train_f1_at_03:0.18572  valid_f1_at_03:0.53185\n","Epoch 6 - train_f1_at_05:0.02311  valid_f1_at_05:0.33200\n",">>>>>>>> Model Improved From 0.470397404703974 ----> 0.5318495778971604\n","other scores here... 0.5318495778971604, 0.33199999999999996\n","Starting 7 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:15<00:00,  1.23s/it, loss=0.00638]\n","100%|| 93/93 [01:04<00:00,  1.45it/s, loss=0.00479]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 - avg_train_loss: 0.00638  avg_val_loss: 0.00479  time: 980s\n","Epoch 7 - train_f1_at_03:0.21600  valid_f1_at_03:0.49028\n","Epoch 7 - train_f1_at_05:0.03251  valid_f1_at_05:0.23151\n","Starting 8 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:12<00:00,  1.23s/it, loss=0.00605]\n","100%|| 93/93 [01:04<00:00,  1.44it/s, loss=0.00477]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 - avg_train_loss: 0.00605  avg_val_loss: 0.00477  time: 978s\n","Epoch 8 - train_f1_at_03:0.25370  valid_f1_at_03:0.50818\n","Epoch 8 - train_f1_at_05:0.04438  valid_f1_at_05:0.26587\n","Starting 9 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:16<00:00,  1.23s/it, loss=0.006]  \n","100%|| 93/93 [01:05<00:00,  1.43it/s, loss=0.00407]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9 - avg_train_loss: 0.00600  avg_val_loss: 0.00407  time: 982s\n","Epoch 9 - train_f1_at_03:0.26109  valid_f1_at_03:0.58996\n","Epoch 9 - train_f1_at_05:0.04626  valid_f1_at_05:0.39315\n",">>>>>>>> Model Improved From 0.5318495778971604 ----> 0.5899573837317028\n","other scores here... 0.5899573837317028, 0.39315002411963335\n","Starting 10 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:17<00:00,  1.23s/it, loss=0.00593]\n","100%|| 93/93 [01:05<00:00,  1.42it/s, loss=0.00392]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10 - avg_train_loss: 0.00593  avg_val_loss: 0.00392  time: 983s\n","Epoch 10 - train_f1_at_03:0.27158  valid_f1_at_03:0.61059\n","Epoch 10 - train_f1_at_05:0.06074  valid_f1_at_05:0.39362\n",">>>>>>>> Model Improved From 0.5899573837317028 ----> 0.6105895606458881\n","other scores here... 0.6105895606458881, 0.3936247283264912\n","Starting 11 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:14<00:00,  1.23s/it, loss=0.00568]\n","100%|| 93/93 [01:05<00:00,  1.43it/s, loss=0.00432]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11 - avg_train_loss: 0.00568  avg_val_loss: 0.00432  time: 980s\n","Epoch 11 - train_f1_at_03:0.30270  valid_f1_at_03:0.56782\n","Epoch 11 - train_f1_at_05:0.07009  valid_f1_at_05:0.32825\n","Starting 12 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:16<00:00,  1.23s/it, loss=0.00541]\n","100%|| 93/93 [01:04<00:00,  1.43it/s, loss=0.00414]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12 - avg_train_loss: 0.00541  avg_val_loss: 0.00414  time: 982s\n","Epoch 12 - train_f1_at_03:0.33108  valid_f1_at_03:0.58135\n","Epoch 12 - train_f1_at_05:0.07928  valid_f1_at_05:0.33183\n","Starting 13 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:16<00:00,  1.23s/it, loss=0.00553]\n","100%|| 93/93 [01:05<00:00,  1.42it/s, loss=0.00367]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13 - avg_train_loss: 0.00553  avg_val_loss: 0.00367  time: 982s\n","Epoch 13 - train_f1_at_03:0.32854  valid_f1_at_03:0.64478\n","Epoch 13 - train_f1_at_05:0.08775  valid_f1_at_05:0.39894\n",">>>>>>>> Model Improved From 0.6105895606458881 ----> 0.644782688428388\n","other scores here... 0.644782688428388, 0.39894001445434835\n","Starting 14 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [16:03<00:00,  1.30s/it, loss=0.00548]\n","100%|| 93/93 [01:05<00:00,  1.42it/s, loss=0.00357]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14 - avg_train_loss: 0.00548  avg_val_loss: 0.00357  time: 1029s\n","Epoch 14 - train_f1_at_03:0.35897  valid_f1_at_03:0.65995\n","Epoch 14 - train_f1_at_05:0.09364  valid_f1_at_05:0.41833\n",">>>>>>>> Model Improved From 0.644782688428388 ----> 0.6599532458190973\n","other scores here... 0.6599532458190973, 0.41832858499525166\n","Starting 15 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:14<00:00,  1.23s/it, loss=0.00527]\n","100%|| 93/93 [01:05<00:00,  1.42it/s, loss=0.00389]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15 - avg_train_loss: 0.00527  avg_val_loss: 0.00389  time: 980s\n","Epoch 15 - train_f1_at_03:0.34881  valid_f1_at_03:0.62082\n","Epoch 15 - train_f1_at_05:0.09691  valid_f1_at_05:0.40544\n","Starting 16 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:13<00:00,  1.23s/it, loss=0.00501]\n","100%|| 93/93 [01:05<00:00,  1.42it/s, loss=0.00391]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16 - avg_train_loss: 0.00501  avg_val_loss: 0.00391  time: 979s\n","Epoch 16 - train_f1_at_03:0.38772  valid_f1_at_03:0.62046\n","Epoch 16 - train_f1_at_05:0.12623  valid_f1_at_05:0.35000\n","Starting 17 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:14<00:00,  1.23s/it, loss=0.0052] \n","100%|| 93/93 [01:04<00:00,  1.43it/s, loss=0.00343]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17 - avg_train_loss: 0.00520  avg_val_loss: 0.00343  time: 980s\n","Epoch 17 - train_f1_at_03:0.37282  valid_f1_at_03:0.67617\n","Epoch 17 - train_f1_at_05:0.11304  valid_f1_at_05:0.44278\n",">>>>>>>> Model Improved From 0.6599532458190973 ----> 0.676165347405453\n","other scores here... 0.676165347405453, 0.4427802480692722\n","Starting 18 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:15<00:00,  1.23s/it, loss=0.00511]\n","100%|| 93/93 [01:05<00:00,  1.43it/s, loss=0.00331]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18 - avg_train_loss: 0.00511  avg_val_loss: 0.00331  time: 982s\n","Epoch 18 - train_f1_at_03:0.37638  valid_f1_at_03:0.68847\n","Epoch 18 - train_f1_at_05:0.11563  valid_f1_at_05:0.49173\n",">>>>>>>> Model Improved From 0.676165347405453 ----> 0.6884669479606188\n","other scores here... 0.6884669479606188, 0.4917289825515523\n","Starting 19 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:12<00:00,  1.23s/it, loss=0.00334]\n","100%|| 93/93 [01:04<00:00,  1.44it/s, loss=0.00409]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19 - avg_train_loss: 0.00334  avg_val_loss: 0.00409  time: 978s\n","Epoch 19 - train_f1_at_03:0.68919  valid_f1_at_03:0.62052\n","Epoch 19 - train_f1_at_05:0.49512  valid_f1_at_05:0.53835\n","Starting 20 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:09<00:00,  1.22s/it, loss=0.00316]\n","100%|| 93/93 [01:04<00:00,  1.44it/s, loss=0.00401]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20 - avg_train_loss: 0.00316  avg_val_loss: 0.00401  time: 975s\n","Epoch 20 - train_f1_at_03:0.70982  valid_f1_at_03:0.63599\n","Epoch 20 - train_f1_at_05:0.55678  valid_f1_at_05:0.56616\n","Starting 21 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:11<00:00,  1.23s/it, loss=0.00331]\n","100%|| 93/93 [01:04<00:00,  1.44it/s, loss=0.00334]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 21 - avg_train_loss: 0.00331  avg_val_loss: 0.00334  time: 976s\n","Epoch 21 - train_f1_at_03:0.69375  valid_f1_at_03:0.69921\n","Epoch 21 - train_f1_at_05:0.53712  valid_f1_at_05:0.65669\n",">>>>>>>> Model Improved From 0.6884669479606188 ----> 0.699205823957644\n","other scores here... 0.699205823957644, 0.6566929133858267\n","Starting 22 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:08<00:00,  1.22s/it, loss=0.00317]\n","100%|| 93/93 [01:03<00:00,  1.47it/s, loss=0.00345]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 22 - avg_train_loss: 0.00317  avg_val_loss: 0.00345  time: 973s\n","Epoch 22 - train_f1_at_03:0.70550  valid_f1_at_03:0.69506\n","Epoch 22 - train_f1_at_05:0.56390  valid_f1_at_05:0.65069\n","Starting 23 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:08<00:00,  1.22s/it, loss=0.00278]\n","100%|| 93/93 [01:04<00:00,  1.45it/s, loss=0.00431]\n","/home/olly/miniconda3/envs/AudioML_3060/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 23 - avg_train_loss: 0.00278  avg_val_loss: 0.00431  time: 974s\n","Epoch 23 - train_f1_at_03:0.74859  valid_f1_at_03:0.63259\n","Epoch 23 - train_f1_at_05:0.61969  valid_f1_at_05:0.56528\n","====================================================================================================\n","Fold 1 Training\n","====================================================================================================\n","Starting 1 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:06<00:00,  1.22s/it, loss=0.0145]\n","100%|| 93/93 [01:02<00:00,  1.48it/s, loss=0.00781]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.01451  avg_val_loss: 0.00781  time: 970s\n","Epoch 1 - train_f1_at_03:0.00488  valid_f1_at_03:0.00000\n","Epoch 1 - train_f1_at_05:0.00215  valid_f1_at_05:0.00000\n",">>>>>>>> Model Improved From -inf ----> 0.0\n","other scores here... 0.0, 0.0\n","Starting 2 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:07<00:00,  1.22s/it, loss=0.00838]\n","100%|| 93/93 [01:03<00:00,  1.46it/s, loss=0.00664]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.00838  avg_val_loss: 0.00664  time: 972s\n","Epoch 2 - train_f1_at_03:0.01406  valid_f1_at_03:0.19196\n","Epoch 2 - train_f1_at_05:0.00000  valid_f1_at_05:0.02554\n",">>>>>>>> Model Improved From 0.0 ----> 0.19196314307652929\n","other scores here... 0.19196314307652929, 0.02554202554202554\n","Starting 3 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:07<00:00,  1.22s/it, loss=0.00769]\n","100%|| 93/93 [01:03<00:00,  1.47it/s, loss=0.00615]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.00769  avg_val_loss: 0.00615  time: 972s\n","Epoch 3 - train_f1_at_03:0.04836  valid_f1_at_03:0.32168\n","Epoch 3 - train_f1_at_05:0.00419  valid_f1_at_05:0.10777\n",">>>>>>>> Model Improved From 0.19196314307652929 ----> 0.3216783216783217\n","other scores here... 0.3216783216783217, 0.10777084515031196\n","Starting 4 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:06<00:00,  1.22s/it, loss=0.00708]\n","100%|| 93/93 [01:03<00:00,  1.46it/s, loss=0.00569]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.00708  avg_val_loss: 0.00569  time: 971s\n","Epoch 4 - train_f1_at_03:0.11411  valid_f1_at_03:0.38282\n","Epoch 4 - train_f1_at_05:0.01190  valid_f1_at_05:0.16474\n",">>>>>>>> Model Improved From 0.3216783216783217 ----> 0.38281582305401957\n","other scores here... 0.38281582305401957, 0.16474464579901155\n","Starting 5 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:08<00:00,  1.22s/it, loss=0.00674]\n","100%|| 93/93 [01:04<00:00,  1.45it/s, loss=0.005]  \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.00674  avg_val_loss: 0.00500  time: 973s\n","Epoch 5 - train_f1_at_03:0.15713  valid_f1_at_03:0.47708\n","Epoch 5 - train_f1_at_05:0.01880  valid_f1_at_05:0.21199\n",">>>>>>>> Model Improved From 0.38281582305401957 ----> 0.47707533831549176\n","other scores here... 0.47707533831549176, 0.2119914346895075\n","Starting 6 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:04<00:00,  1.22s/it, loss=0.00661]\n","100%|| 93/93 [01:03<00:00,  1.46it/s, loss=0.00457]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 - avg_train_loss: 0.00661  avg_val_loss: 0.00457  time: 969s\n","Epoch 6 - train_f1_at_03:0.18411  valid_f1_at_03:0.52750\n","Epoch 6 - train_f1_at_05:0.02417  valid_f1_at_05:0.27552\n",">>>>>>>> Model Improved From 0.47707533831549176 ----> 0.5275024295432459\n","other scores here... 0.5275024295432459, 0.2755233910571207\n","Starting 7 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:03<00:00,  1.22s/it, loss=0.00632]\n","100%|| 93/93 [01:02<00:00,  1.49it/s, loss=0.00484]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 - avg_train_loss: 0.00632  avg_val_loss: 0.00484  time: 967s\n","Epoch 7 - train_f1_at_03:0.21234  valid_f1_at_03:0.49383\n","Epoch 7 - train_f1_at_05:0.03448  valid_f1_at_05:0.20920\n","Starting 8 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:05<00:00,  1.22s/it, loss=0.00601]\n","100%|| 93/93 [01:03<00:00,  1.47it/s, loss=0.00471]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 - avg_train_loss: 0.00601  avg_val_loss: 0.00471  time: 969s\n","Epoch 8 - train_f1_at_03:0.26310  valid_f1_at_03:0.52409\n","Epoch 8 - train_f1_at_05:0.05358  valid_f1_at_05:0.26387\n","Starting 9 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:04<00:00,  1.22s/it, loss=0.00594]\n","100%|| 93/93 [01:03<00:00,  1.47it/s, loss=0.00411]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9 - avg_train_loss: 0.00594  avg_val_loss: 0.00411  time: 969s\n","Epoch 9 - train_f1_at_03:0.25654  valid_f1_at_03:0.58613\n","Epoch 9 - train_f1_at_05:0.04910  valid_f1_at_05:0.32111\n",">>>>>>>> Model Improved From 0.5275024295432459 ----> 0.5861348528015196\n","other scores here... 0.5861348528015196, 0.32110552763819095\n","Starting 10 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:06<00:00,  1.22s/it, loss=0.00601]\n","100%|| 93/93 [01:03<00:00,  1.47it/s, loss=0.00392]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10 - avg_train_loss: 0.00601  avg_val_loss: 0.00392  time: 970s\n","Epoch 10 - train_f1_at_03:0.26021  valid_f1_at_03:0.61701\n","Epoch 10 - train_f1_at_05:0.04882  valid_f1_at_05:0.37122\n",">>>>>>>> Model Improved From 0.5861348528015196 ----> 0.6170133729569093\n","other scores here... 0.6170133729569093, 0.37121951219512195\n","Starting 11 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:04<00:00,  1.22s/it, loss=0.00568]\n","100%|| 93/93 [01:03<00:00,  1.47it/s, loss=0.00423]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11 - avg_train_loss: 0.00568  avg_val_loss: 0.00423  time: 968s\n","Epoch 11 - train_f1_at_03:0.30218  valid_f1_at_03:0.57313\n","Epoch 11 - train_f1_at_05:0.06803  valid_f1_at_05:0.28966\n","Starting 12 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:07<00:00,  1.22s/it, loss=0.00556]\n","100%|| 93/93 [01:03<00:00,  1.46it/s, loss=0.00431]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12 - avg_train_loss: 0.00556  avg_val_loss: 0.00431  time: 972s\n","Epoch 12 - train_f1_at_03:0.31232  valid_f1_at_03:0.59329\n","Epoch 12 - train_f1_at_05:0.06171  valid_f1_at_05:0.29460\n","Starting 13 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:05<00:00,  1.22s/it, loss=0.00553]\n","100%|| 93/93 [01:03<00:00,  1.47it/s, loss=0.00366]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13 - avg_train_loss: 0.00553  avg_val_loss: 0.00366  time: 969s\n","Epoch 13 - train_f1_at_03:0.32364  valid_f1_at_03:0.65776\n","Epoch 13 - train_f1_at_05:0.07653  valid_f1_at_05:0.40933\n",">>>>>>>> Model Improved From 0.6170133729569093 ----> 0.6577569080729637\n","other scores here... 0.6577569080729637, 0.40932889100428366\n","Starting 14 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:07<00:00,  1.22s/it, loss=0.00551]\n","100%|| 93/93 [01:03<00:00,  1.46it/s, loss=0.00356]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14 - avg_train_loss: 0.00551  avg_val_loss: 0.00356  time: 972s\n","Epoch 14 - train_f1_at_03:0.32382  valid_f1_at_03:0.66248\n","Epoch 14 - train_f1_at_05:0.08606  valid_f1_at_05:0.43690\n",">>>>>>>> Model Improved From 0.6577569080729637 ----> 0.6624843161856964\n","other scores here... 0.6624843161856964, 0.4369000234137204\n","Starting 15 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:07<00:00,  1.22s/it, loss=0.0053] \n","100%|| 93/93 [01:03<00:00,  1.47it/s, loss=0.00393]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15 - avg_train_loss: 0.00530  avg_val_loss: 0.00393  time: 972s\n","Epoch 15 - train_f1_at_03:0.34840  valid_f1_at_03:0.61840\n","Epoch 15 - train_f1_at_05:0.09334  valid_f1_at_05:0.28689\n","Starting 16 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:06<00:00,  1.22s/it, loss=0.00503]\n","100%|| 93/93 [01:03<00:00,  1.47it/s, loss=0.00401]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16 - avg_train_loss: 0.00503  avg_val_loss: 0.00401  time: 970s\n","Epoch 16 - train_f1_at_03:0.38367  valid_f1_at_03:0.60509\n","Epoch 16 - train_f1_at_05:0.12550  valid_f1_at_05:0.30371\n","Starting 17 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:05<00:00,  1.22s/it, loss=0.00526]\n","100%|| 93/93 [01:02<00:00,  1.48it/s, loss=0.00337]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17 - avg_train_loss: 0.00526  avg_val_loss: 0.00337  time: 969s\n","Epoch 17 - train_f1_at_03:0.35661  valid_f1_at_03:0.70051\n","Epoch 17 - train_f1_at_05:0.09773  valid_f1_at_05:0.43962\n",">>>>>>>> Model Improved From 0.6624843161856964 ----> 0.7005093975057087\n","other scores here... 0.7005093975057087, 0.43961691193646346\n","Starting 18 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:07<00:00,  1.22s/it, loss=0.00514]\n","100%|| 93/93 [01:03<00:00,  1.47it/s, loss=0.00341]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18 - avg_train_loss: 0.00514  avg_val_loss: 0.00341  time: 971s\n","Epoch 18 - train_f1_at_03:0.38113  valid_f1_at_03:0.68991\n","Epoch 18 - train_f1_at_05:0.11516  valid_f1_at_05:0.43262\n","Starting 19 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:07<00:00,  1.22s/it, loss=0.00336]\n","100%|| 93/93 [01:03<00:00,  1.46it/s, loss=0.00409]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19 - avg_train_loss: 0.00336  avg_val_loss: 0.00409  time: 971s\n","Epoch 19 - train_f1_at_03:0.68811  valid_f1_at_03:0.63309\n","Epoch 19 - train_f1_at_05:0.49070  valid_f1_at_05:0.55178\n","Starting 20 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:03<00:00,  1.22s/it, loss=0.00314]\n","100%|| 93/93 [01:04<00:00,  1.44it/s, loss=0.0037] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20 - avg_train_loss: 0.00314  avg_val_loss: 0.00370  time: 969s\n","Epoch 20 - train_f1_at_03:0.70897  valid_f1_at_03:0.65364\n","Epoch 20 - train_f1_at_05:0.55244  valid_f1_at_05:0.58430\n","Starting 21 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:05<00:00,  1.22s/it, loss=0.00329]\n","100%|| 93/93 [01:03<00:00,  1.47it/s, loss=0.00328]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 21 - avg_train_loss: 0.00329  avg_val_loss: 0.00328  time: 969s\n","Epoch 21 - train_f1_at_03:0.69238  valid_f1_at_03:0.71036\n","Epoch 21 - train_f1_at_05:0.54205  valid_f1_at_05:0.65601\n",">>>>>>>> Model Improved From 0.7005093975057087 ----> 0.7103608076795764\n","other scores here... 0.7103608076795764, 0.6560094730609829\n","Starting 22 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:10<00:00,  1.23s/it, loss=0.00319]\n","100%|| 93/93 [01:03<00:00,  1.46it/s, loss=0.0034] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 22 - avg_train_loss: 0.00319  avg_val_loss: 0.00340  time: 974s\n","Epoch 22 - train_f1_at_03:0.70677  valid_f1_at_03:0.70114\n","Epoch 22 - train_f1_at_05:0.55507  valid_f1_at_05:0.65365\n","Starting 23 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:06<00:00,  1.22s/it, loss=0.00279]\n","100%|| 93/93 [01:03<00:00,  1.47it/s, loss=0.00408]\n","/home/olly/miniconda3/envs/AudioML_3060/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 23 - avg_train_loss: 0.00279  avg_val_loss: 0.00408  time: 971s\n","Epoch 23 - train_f1_at_03:0.74771  valid_f1_at_03:0.63405\n","Epoch 23 - train_f1_at_05:0.62003  valid_f1_at_05:0.56450\n","====================================================================================================\n","Fold 2 Training\n","====================================================================================================\n","Starting 1 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [16:48<00:00,  1.36s/it, loss=0.0147]\n","100%|| 93/93 [01:18<00:00,  1.18it/s, loss=0.00787]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.01471  avg_val_loss: 0.00787  time: 1087s\n","Epoch 1 - train_f1_at_03:0.00377  valid_f1_at_03:0.00060\n","Epoch 1 - train_f1_at_05:0.00174  valid_f1_at_05:0.00000\n",">>>>>>>> Model Improved From -inf ----> 0.0005961251862891208\n","other scores here... 0.0005961251862891208, 0.0\n","Starting 2 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:02<00:00,  1.22s/it, loss=0.0084] \n","100%|| 93/93 [01:02<00:00,  1.50it/s, loss=0.00676]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.00840  avg_val_loss: 0.00676  time: 966s\n","Epoch 2 - train_f1_at_03:0.01658  valid_f1_at_03:0.19570\n","Epoch 2 - train_f1_at_05:0.00045  valid_f1_at_05:0.03399\n",">>>>>>>> Model Improved From 0.0005961251862891208 ----> 0.19570164348925412\n","other scores here... 0.19570164348925412, 0.033987694110752996\n","Starting 3 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [14:52<00:00,  1.20s/it, loss=0.00769]\n","100%|| 93/93 [01:00<00:00,  1.53it/s, loss=0.00607]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.00769  avg_val_loss: 0.00607  time: 954s\n","Epoch 3 - train_f1_at_03:0.05483  valid_f1_at_03:0.33489\n","Epoch 3 - train_f1_at_05:0.00300  valid_f1_at_05:0.11666\n",">>>>>>>> Model Improved From 0.19570164348925412 ----> 0.33489200623469156\n","other scores here... 0.33489200623469156, 0.11665731912507012\n","Starting 4 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [14:46<00:00,  1.19s/it, loss=0.00707]\n","100%|| 93/93 [01:01<00:00,  1.51it/s, loss=0.00593]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.00707  avg_val_loss: 0.00593  time: 949s\n","Epoch 4 - train_f1_at_03:0.10755  valid_f1_at_03:0.35656\n","Epoch 4 - train_f1_at_05:0.01075  valid_f1_at_05:0.12865\n",">>>>>>>> Model Improved From 0.33489200623469156 ----> 0.35655828356558283\n","other scores here... 0.35655828356558283, 0.1286549707602339\n","Starting 5 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [14:49<00:00,  1.20s/it, loss=0.00677]\n","100%|| 93/93 [01:02<00:00,  1.49it/s, loss=0.0052] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.00677  avg_val_loss: 0.00520  time: 952s\n","Epoch 5 - train_f1_at_03:0.16245  valid_f1_at_03:0.45856\n","Epoch 5 - train_f1_at_05:0.01723  valid_f1_at_05:0.19301\n",">>>>>>>> Model Improved From 0.35655828356558283 ----> 0.4585567010309278\n","other scores here... 0.4585567010309278, 0.19301075268817203\n","Starting 6 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [14:50<00:00,  1.20s/it, loss=0.00661]\n","100%|| 93/93 [01:01<00:00,  1.51it/s, loss=0.00468]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 - avg_train_loss: 0.00661  avg_val_loss: 0.00468  time: 953s\n","Epoch 6 - train_f1_at_03:0.18010  valid_f1_at_03:0.53414\n","Epoch 6 - train_f1_at_05:0.02349  valid_f1_at_05:0.29200\n",">>>>>>>> Model Improved From 0.4585567010309278 ----> 0.5341373273682163\n","other scores here... 0.5341373273682163, 0.292004048582996\n","Starting 7 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [16:08<00:00,  1.30s/it, loss=0.00632]\n","100%|| 93/93 [01:08<00:00,  1.36it/s, loss=0.00489]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 - avg_train_loss: 0.00632  avg_val_loss: 0.00489  time: 1037s\n","Epoch 7 - train_f1_at_03:0.21370  valid_f1_at_03:0.50514\n","Epoch 7 - train_f1_at_05:0.03167  valid_f1_at_05:0.28397\n","Starting 8 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [16:22<00:00,  1.32s/it, loss=0.00603]\n","100%|| 93/93 [01:07<00:00,  1.39it/s, loss=0.00486]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 - avg_train_loss: 0.00603  avg_val_loss: 0.00486  time: 1050s\n","Epoch 8 - train_f1_at_03:0.25659  valid_f1_at_03:0.51085\n","Epoch 8 - train_f1_at_05:0.05523  valid_f1_at_05:0.28738\n","Starting 9 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [16:18<00:00,  1.32s/it, loss=0.00604]\n","100%|| 93/93 [01:07<00:00,  1.38it/s, loss=0.00412]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9 - avg_train_loss: 0.00604  avg_val_loss: 0.00412  time: 1047s\n","Epoch 9 - train_f1_at_03:0.24373  valid_f1_at_03:0.60074\n","Epoch 9 - train_f1_at_05:0.04332  valid_f1_at_05:0.35733\n",">>>>>>>> Model Improved From 0.5341373273682163 ----> 0.6007448789571695\n","other scores here... 0.6007448789571695, 0.3573346350988528\n","Starting 10 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [16:17<00:00,  1.32s/it, loss=0.00599]\n","100%|| 93/93 [01:07<00:00,  1.37it/s, loss=0.00397]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10 - avg_train_loss: 0.00599  avg_val_loss: 0.00397  time: 1046s\n","Epoch 10 - train_f1_at_03:0.26731  valid_f1_at_03:0.61780\n","Epoch 10 - train_f1_at_05:0.05884  valid_f1_at_05:0.40388\n",">>>>>>>> Model Improved From 0.6007448789571695 ----> 0.6178049231908199\n","other scores here... 0.6178049231908199, 0.40387798533932373\n","Starting 11 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [16:19<00:00,  1.32s/it, loss=0.0057] \n","100%|| 93/93 [01:08<00:00,  1.36it/s, loss=0.00428]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11 - avg_train_loss: 0.00570  avg_val_loss: 0.00428  time: 1049s\n","Epoch 11 - train_f1_at_03:0.29903  valid_f1_at_03:0.58784\n","Epoch 11 - train_f1_at_05:0.07090  valid_f1_at_05:0.31247\n","Starting 12 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:46<00:00,  1.27s/it, loss=0.00551]\n","100%|| 93/93 [01:08<00:00,  1.36it/s, loss=0.00445]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12 - avg_train_loss: 0.00551  avg_val_loss: 0.00445  time: 1016s\n","Epoch 12 - train_f1_at_03:0.31601  valid_f1_at_03:0.56988\n","Epoch 12 - train_f1_at_05:0.07527  valid_f1_at_05:0.38249\n","Starting 13 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:51<00:00,  1.28s/it, loss=0.00557]\n","100%|| 93/93 [01:08<00:00,  1.36it/s, loss=0.00366]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13 - avg_train_loss: 0.00557  avg_val_loss: 0.00366  time: 1020s\n","Epoch 13 - train_f1_at_03:0.31591  valid_f1_at_03:0.65044\n","Epoch 13 - train_f1_at_05:0.08093  valid_f1_at_05:0.46639\n",">>>>>>>> Model Improved From 0.6178049231908199 ----> 0.6504440497335702\n","other scores here... 0.6504440497335702, 0.46639418710263386\n","Starting 14 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:52<00:00,  1.28s/it, loss=0.00548]\n","100%|| 93/93 [01:13<00:00,  1.27it/s, loss=0.00365]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14 - avg_train_loss: 0.00548  avg_val_loss: 0.00365  time: 1026s\n","Epoch 14 - train_f1_at_03:0.33403  valid_f1_at_03:0.65490\n","Epoch 14 - train_f1_at_05:0.09245  valid_f1_at_05:0.42757\n",">>>>>>>> Model Improved From 0.6504440497335702 ----> 0.6548984995586937\n","other scores here... 0.6548984995586937, 0.42757335817419656\n","Starting 15 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:52<00:00,  1.28s/it, loss=0.00522]\n","100%|| 93/93 [01:15<00:00,  1.24it/s, loss=0.00405]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15 - avg_train_loss: 0.00522  avg_val_loss: 0.00405  time: 1028s\n","Epoch 15 - train_f1_at_03:0.35388  valid_f1_at_03:0.61445\n","Epoch 15 - train_f1_at_05:0.10110  valid_f1_at_05:0.35139\n","Starting 16 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [16:05<00:00,  1.30s/it, loss=0.00508]\n","100%|| 93/93 [01:03<00:00,  1.46it/s, loss=0.00403]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16 - avg_train_loss: 0.00508  avg_val_loss: 0.00403  time: 1030s\n","Epoch 16 - train_f1_at_03:0.36453  valid_f1_at_03:0.61243\n","Epoch 16 - train_f1_at_05:0.11094  valid_f1_at_05:0.39868\n","Starting 17 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:07<00:00,  1.22s/it, loss=0.00522]\n","100%|| 93/93 [01:04<00:00,  1.44it/s, loss=0.00347]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17 - avg_train_loss: 0.00522  avg_val_loss: 0.00347  time: 972s\n","Epoch 17 - train_f1_at_03:0.35688  valid_f1_at_03:0.67865\n","Epoch 17 - train_f1_at_05:0.10071  valid_f1_at_05:0.47389\n",">>>>>>>> Model Improved From 0.6548984995586937 ----> 0.6786454733932273\n","other scores here... 0.6786454733932273, 0.4738865023739543\n","Starting 18 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:08<00:00,  1.22s/it, loss=0.00515]\n","100%|| 93/93 [01:03<00:00,  1.45it/s, loss=0.00348]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18 - avg_train_loss: 0.00515  avg_val_loss: 0.00348  time: 973s\n","Epoch 18 - train_f1_at_03:0.36787  valid_f1_at_03:0.67653\n","Epoch 18 - train_f1_at_05:0.11350  valid_f1_at_05:0.43843\n","Starting 19 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:06<00:00,  1.22s/it, loss=0.00341]\n","100%|| 93/93 [01:03<00:00,  1.47it/s, loss=0.00418]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19 - avg_train_loss: 0.00341  avg_val_loss: 0.00418  time: 971s\n","Epoch 19 - train_f1_at_03:0.68117  valid_f1_at_03:0.60465\n","Epoch 19 - train_f1_at_05:0.47784  valid_f1_at_05:0.51166\n","Starting 20 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:08<00:00,  1.22s/it, loss=0.00318]\n","100%|| 93/93 [01:04<00:00,  1.45it/s, loss=0.00376]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20 - avg_train_loss: 0.00318  avg_val_loss: 0.00376  time: 974s\n","Epoch 20 - train_f1_at_03:0.70237  valid_f1_at_03:0.65757\n","Epoch 20 - train_f1_at_05:0.54755  valid_f1_at_05:0.56039\n","Starting 21 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [17:10<00:00,  1.39s/it, loss=0.00339]\n","100%|| 93/93 [01:18<00:00,  1.18it/s, loss=0.00341]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 21 - avg_train_loss: 0.00339  avg_val_loss: 0.00341  time: 1110s\n","Epoch 21 - train_f1_at_03:0.68392  valid_f1_at_03:0.70714\n","Epoch 21 - train_f1_at_05:0.51776  valid_f1_at_05:0.65602\n",">>>>>>>> Model Improved From 0.6786454733932273 ----> 0.7071440356376835\n","other scores here... 0.7071440356376835, 0.6560249172668873\n","Starting 22 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [17:06<00:00,  1.38s/it, loss=0.0032] \n","100%|| 93/93 [01:10<00:00,  1.31it/s, loss=0.00354]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 22 - avg_train_loss: 0.00320  avg_val_loss: 0.00354  time: 1098s\n","Epoch 22 - train_f1_at_03:0.70435  valid_f1_at_03:0.70435\n","Epoch 22 - train_f1_at_05:0.55600  valid_f1_at_05:0.66227\n","Starting 23 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:13<00:00,  1.23s/it, loss=0.00282]\n","100%|| 93/93 [01:04<00:00,  1.44it/s, loss=0.00396]\n","/home/olly/miniconda3/envs/AudioML_3060/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 23 - avg_train_loss: 0.00282  avg_val_loss: 0.00396  time: 979s\n","Epoch 23 - train_f1_at_03:0.74303  valid_f1_at_03:0.66264\n","Epoch 23 - train_f1_at_05:0.61200  valid_f1_at_05:0.59830\n","====================================================================================================\n","Fold 3 Training\n","====================================================================================================\n","Starting 1 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [16:04<00:00,  1.30s/it, loss=0.0152]\n","100%|| 93/93 [01:03<00:00,  1.47it/s, loss=0.00788]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.01515  avg_val_loss: 0.00788  time: 1028s\n","Epoch 1 - train_f1_at_03:0.00435  valid_f1_at_03:0.00000\n","Epoch 1 - train_f1_at_05:0.00252  valid_f1_at_05:0.00000\n",">>>>>>>> Model Improved From -inf ----> 0.0\n","other scores here... 0.0, 0.0\n","Starting 2 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:11<00:00,  1.23s/it, loss=0.00851]\n","100%|| 93/93 [01:04<00:00,  1.44it/s, loss=0.00688]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.00851  avg_val_loss: 0.00688  time: 977s\n","Epoch 2 - train_f1_at_03:0.00582  valid_f1_at_03:0.13981\n","Epoch 2 - train_f1_at_05:0.00000  valid_f1_at_05:0.01374\n",">>>>>>>> Model Improved From 0.0 ----> 0.1398110661268556\n","other scores here... 0.1398110661268556, 0.013743651030773825\n","Starting 3 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:12<00:00,  1.23s/it, loss=0.00783]\n","100%|| 93/93 [01:03<00:00,  1.46it/s, loss=0.00629]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.00783  avg_val_loss: 0.00629  time: 977s\n","Epoch 3 - train_f1_at_03:0.03531  valid_f1_at_03:0.29521\n","Epoch 3 - train_f1_at_05:0.00045  valid_f1_at_05:0.09226\n",">>>>>>>> Model Improved From 0.1398110661268556 ----> 0.29520795660036164\n","other scores here... 0.29520795660036164, 0.09226361031518623\n","Starting 4 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:09<00:00,  1.22s/it, loss=0.00716]\n","100%|| 93/93 [01:04<00:00,  1.44it/s, loss=0.00591]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.00716  avg_val_loss: 0.00591  time: 975s\n","Epoch 4 - train_f1_at_03:0.09733  valid_f1_at_03:0.31712\n","Epoch 4 - train_f1_at_05:0.00731  valid_f1_at_05:0.10427\n",">>>>>>>> Model Improved From 0.29520795660036164 ----> 0.31711794401101423\n","other scores here... 0.31711794401101423, 0.10427350427350429\n","Starting 5 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:10<00:00,  1.23s/it, loss=0.00676]\n","100%|| 93/93 [01:03<00:00,  1.46it/s, loss=0.00505]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.00676  avg_val_loss: 0.00505  time: 975s\n","Epoch 5 - train_f1_at_03:0.15662  valid_f1_at_03:0.47080\n","Epoch 5 - train_f1_at_05:0.02301  valid_f1_at_05:0.26372\n",">>>>>>>> Model Improved From 0.31711794401101423 ----> 0.4707957663661309\n","other scores here... 0.4707957663661309, 0.2637191157347204\n","Starting 6 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:12<00:00,  1.23s/it, loss=0.00667]\n","100%|| 93/93 [01:03<00:00,  1.46it/s, loss=0.00462]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 - avg_train_loss: 0.00667  avg_val_loss: 0.00462  time: 976s\n","Epoch 6 - train_f1_at_03:0.15986  valid_f1_at_03:0.52840\n","Epoch 6 - train_f1_at_05:0.02242  valid_f1_at_05:0.30147\n",">>>>>>>> Model Improved From 0.4707957663661309 ----> 0.5284046692607004\n","other scores here... 0.5284046692607004, 0.3014743263853584\n","Starting 7 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:11<00:00,  1.23s/it, loss=0.00639]\n","100%|| 93/93 [01:04<00:00,  1.44it/s, loss=0.00474]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 - avg_train_loss: 0.00639  avg_val_loss: 0.00474  time: 977s\n","Epoch 7 - train_f1_at_03:0.20547  valid_f1_at_03:0.51751\n","Epoch 7 - train_f1_at_05:0.03253  valid_f1_at_05:0.29046\n","Starting 8 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:09<00:00,  1.22s/it, loss=0.00609]\n","100%|| 93/93 [01:03<00:00,  1.46it/s, loss=0.005]  \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 - avg_train_loss: 0.00609  avg_val_loss: 0.00500  time: 974s\n","Epoch 8 - train_f1_at_03:0.24434  valid_f1_at_03:0.47154\n","Epoch 8 - train_f1_at_05:0.04245  valid_f1_at_05:0.19827\n","Starting 9 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:08<00:00,  1.22s/it, loss=0.00601]\n","100%|| 93/93 [01:04<00:00,  1.45it/s, loss=0.00412]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9 - avg_train_loss: 0.00601  avg_val_loss: 0.00412  time: 973s\n","Epoch 9 - train_f1_at_03:0.25869  valid_f1_at_03:0.59384\n","Epoch 9 - train_f1_at_05:0.05198  valid_f1_at_05:0.36644\n",">>>>>>>> Model Improved From 0.5284046692607004 ----> 0.593841642228739\n","other scores here... 0.593841642228739, 0.3664383561643835\n","Starting 10 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:08<00:00,  1.22s/it, loss=0.00596]\n","100%|| 93/93 [01:03<00:00,  1.46it/s, loss=0.00396]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10 - avg_train_loss: 0.00596  avg_val_loss: 0.00396  time: 972s\n","Epoch 10 - train_f1_at_03:0.26734  valid_f1_at_03:0.61823\n","Epoch 10 - train_f1_at_05:0.05836  valid_f1_at_05:0.37162\n",">>>>>>>> Model Improved From 0.593841642228739 ----> 0.6182288777962655\n","other scores here... 0.6182288777962655, 0.37161667885881494\n","Starting 11 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:16<00:00,  1.23s/it, loss=0.00572]\n","100%|| 93/93 [01:11<00:00,  1.31it/s, loss=0.00427]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11 - avg_train_loss: 0.00572  avg_val_loss: 0.00427  time: 988s\n","Epoch 11 - train_f1_at_03:0.29799  valid_f1_at_03:0.58058\n","Epoch 11 - train_f1_at_05:0.06947  valid_f1_at_05:0.31135\n","Starting 12 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [17:12<00:00,  1.39s/it, loss=0.00552]\n","100%|| 93/93 [01:20<00:00,  1.15it/s, loss=0.00423]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12 - avg_train_loss: 0.00552  avg_val_loss: 0.00423  time: 1114s\n","Epoch 12 - train_f1_at_03:0.31441  valid_f1_at_03:0.58808\n","Epoch 12 - train_f1_at_05:0.07327  valid_f1_at_05:0.32843\n","Starting 13 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [17:32<00:00,  1.42s/it, loss=0.0056] \n","100%|| 93/93 [01:13<00:00,  1.26it/s, loss=0.00363]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13 - avg_train_loss: 0.00560  avg_val_loss: 0.00363  time: 1127s\n","Epoch 13 - train_f1_at_03:0.30684  valid_f1_at_03:0.65157\n","Epoch 13 - train_f1_at_05:0.06429  valid_f1_at_05:0.42934\n",">>>>>>>> Model Improved From 0.6182288777962655 ----> 0.6515723270440251\n","other scores here... 0.6515723270440251, 0.42934399247589944\n","Starting 14 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [17:12<00:00,  1.39s/it, loss=0.00553]\n","100%|| 93/93 [01:15<00:00,  1.23it/s, loss=0.0036] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14 - avg_train_loss: 0.00553  avg_val_loss: 0.00360  time: 1109s\n","Epoch 14 - train_f1_at_03:0.31823  valid_f1_at_03:0.65813\n","Epoch 14 - train_f1_at_05:0.07746  valid_f1_at_05:0.44604\n",">>>>>>>> Model Improved From 0.6515723270440251 ----> 0.6581301526048061\n","other scores here... 0.6581301526048061, 0.44603983325613705\n","Starting 15 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [17:38<00:00,  1.42s/it, loss=0.00527]\n","100%|| 93/93 [01:15<00:00,  1.23it/s, loss=0.00408]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15 - avg_train_loss: 0.00527  avg_val_loss: 0.00408  time: 1135s\n","Epoch 15 - train_f1_at_03:0.33616  valid_f1_at_03:0.59219\n","Epoch 15 - train_f1_at_05:0.09417  valid_f1_at_05:0.34712\n","Starting 16 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [17:27<00:00,  1.41s/it, loss=0.00512]\n","100%|| 93/93 [01:18<00:00,  1.19it/s, loss=0.00383]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16 - avg_train_loss: 0.00512  avg_val_loss: 0.00383  time: 1126s\n","Epoch 16 - train_f1_at_03:0.37549  valid_f1_at_03:0.63732\n","Epoch 16 - train_f1_at_05:0.10834  valid_f1_at_05:0.42269\n","Starting 17 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [17:34<00:00,  1.42s/it, loss=0.00514]\n","100%|| 93/93 [01:24<00:00,  1.10it/s, loss=0.00341]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17 - avg_train_loss: 0.00514  avg_val_loss: 0.00341  time: 1140s\n","Epoch 17 - train_f1_at_03:0.35826  valid_f1_at_03:0.68555\n","Epoch 17 - train_f1_at_05:0.10825  valid_f1_at_05:0.47626\n",">>>>>>>> Model Improved From 0.6581301526048061 ----> 0.6855465377309619\n","other scores here... 0.6855465377309619, 0.4762553965007953\n","Starting 18 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [17:25<00:00,  1.41s/it, loss=0.00509]\n","100%|| 93/93 [01:16<00:00,  1.22it/s, loss=0.00337]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18 - avg_train_loss: 0.00509  avg_val_loss: 0.00337  time: 1122s\n","Epoch 18 - train_f1_at_03:0.38348  valid_f1_at_03:0.68869\n","Epoch 18 - train_f1_at_05:0.11967  valid_f1_at_05:0.47786\n",">>>>>>>> Model Improved From 0.6855465377309619 ----> 0.6886907883237197\n","other scores here... 0.6886907883237197, 0.47785600726777194\n","Starting 19 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [18:11<00:00,  1.47s/it, loss=0.00337]\n","100%|| 93/93 [01:18<00:00,  1.18it/s, loss=0.00405]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19 - avg_train_loss: 0.00337  avg_val_loss: 0.00405  time: 1171s\n","Epoch 19 - train_f1_at_03:0.68385  valid_f1_at_03:0.63532\n","Epoch 19 - train_f1_at_05:0.48635  valid_f1_at_05:0.56436\n","Starting 20 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:22<00:00,  1.24s/it, loss=0.00313]\n","100%|| 93/93 [01:06<00:00,  1.39it/s, loss=0.00414]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20 - avg_train_loss: 0.00313  avg_val_loss: 0.00414  time: 990s\n","Epoch 20 - train_f1_at_03:0.71590  valid_f1_at_03:0.66256\n","Epoch 20 - train_f1_at_05:0.55855  valid_f1_at_05:0.63732\n","Starting 21 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:19<00:00,  1.24s/it, loss=0.00327]\n","100%|| 93/93 [01:07<00:00,  1.38it/s, loss=0.00333]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 21 - avg_train_loss: 0.00327  avg_val_loss: 0.00333  time: 987s\n","Epoch 21 - train_f1_at_03:0.69984  valid_f1_at_03:0.70702\n","Epoch 21 - train_f1_at_05:0.55180  valid_f1_at_05:0.66016\n",">>>>>>>> Model Improved From 0.6886907883237197 ----> 0.7070241816088172\n","other scores here... 0.7070241816088172, 0.66015625\n","Starting 22 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:20<00:00,  1.24s/it, loss=0.00319]\n","100%|| 93/93 [01:05<00:00,  1.41it/s, loss=0.00353]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 22 - avg_train_loss: 0.00319  avg_val_loss: 0.00353  time: 987s\n","Epoch 22 - train_f1_at_03:0.70616  valid_f1_at_03:0.69916\n","Epoch 22 - train_f1_at_05:0.56140  valid_f1_at_05:0.65925\n","Starting 23 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:20<00:00,  1.24s/it, loss=0.00281]\n","100%|| 93/93 [01:06<00:00,  1.39it/s, loss=0.00392]\n","/home/olly/miniconda3/envs/AudioML_3060/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 23 - avg_train_loss: 0.00281  avg_val_loss: 0.00392  time: 988s\n","Epoch 23 - train_f1_at_03:0.74489  valid_f1_at_03:0.66532\n","Epoch 23 - train_f1_at_05:0.61485  valid_f1_at_05:0.60507\n","====================================================================================================\n","Fold 4 Training\n","====================================================================================================\n","Starting 1 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:18<00:00,  1.24s/it, loss=0.0147]\n","100%|| 93/93 [01:07<00:00,  1.38it/s, loss=0.00784]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.01467  avg_val_loss: 0.00784  time: 987s\n","Epoch 1 - train_f1_at_03:0.00348  valid_f1_at_03:0.00120\n","Epoch 1 - train_f1_at_05:0.00108  valid_f1_at_05:0.00000\n",">>>>>>>> Model Improved From -inf ----> 0.001199760047990402\n","other scores here... 0.001199760047990402, 0.0\n","Starting 2 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [16:12<00:00,  1.31s/it, loss=0.00845]\n","100%|| 93/93 [01:21<00:00,  1.14it/s, loss=0.0068] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.00845  avg_val_loss: 0.00680  time: 1055s\n","Epoch 2 - train_f1_at_03:0.01861  valid_f1_at_03:0.18256\n","Epoch 2 - train_f1_at_05:0.00090  valid_f1_at_05:0.03016\n",">>>>>>>> Model Improved From 0.001199760047990402 ----> 0.18256200460240346\n","other scores here... 0.18256200460240346, 0.03015966883500887\n","Starting 3 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [18:39<00:00,  1.51s/it, loss=0.00776]\n","100%|| 93/93 [01:23<00:00,  1.12it/s, loss=0.00615]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.00776  avg_val_loss: 0.00615  time: 1204s\n","Epoch 3 - train_f1_at_03:0.05383  valid_f1_at_03:0.31282\n","Epoch 3 - train_f1_at_05:0.00464  valid_f1_at_05:0.12521\n",">>>>>>>> Model Improved From 0.18256200460240346 ----> 0.312821660326695\n","other scores here... 0.312821660326695, 0.12521055586749016\n","Starting 4 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [17:50<00:00,  1.44s/it, loss=0.0071] \n","100%|| 93/93 [01:15<00:00,  1.23it/s, loss=0.00613]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.00710  avg_val_loss: 0.00613  time: 1147s\n","Epoch 4 - train_f1_at_03:0.10945  valid_f1_at_03:0.33340\n","Epoch 4 - train_f1_at_05:0.00777  valid_f1_at_05:0.11820\n",">>>>>>>> Model Improved From 0.312821660326695 ----> 0.3334043913877638\n","other scores here... 0.3334043913877638, 0.11820462782269306\n","Starting 5 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:17<00:00,  1.24s/it, loss=0.00677]\n","100%|| 93/93 [01:04<00:00,  1.43it/s, loss=0.00518]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 - avg_train_loss: 0.00677  avg_val_loss: 0.00518  time: 983s\n","Epoch 5 - train_f1_at_03:0.15280  valid_f1_at_03:0.47270\n","Epoch 5 - train_f1_at_05:0.01647  valid_f1_at_05:0.24298\n",">>>>>>>> Model Improved From 0.3334043913877638 ----> 0.47269828616978876\n","other scores here... 0.47269828616978876, 0.24298084492259248\n","Starting 6 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:12<00:00,  1.23s/it, loss=0.0066] \n","100%|| 93/93 [01:04<00:00,  1.45it/s, loss=0.00459]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 - avg_train_loss: 0.00660  avg_val_loss: 0.00459  time: 977s\n","Epoch 6 - train_f1_at_03:0.18122  valid_f1_at_03:0.52980\n","Epoch 6 - train_f1_at_05:0.02516  valid_f1_at_05:0.31970\n",">>>>>>>> Model Improved From 0.47269828616978876 ----> 0.5297962322183776\n","other scores here... 0.5297962322183776, 0.3196988707653701\n","Starting 7 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:10<00:00,  1.23s/it, loss=0.00635]\n","100%|| 93/93 [01:04<00:00,  1.45it/s, loss=0.00491]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 - avg_train_loss: 0.00635  avg_val_loss: 0.00491  time: 975s\n","Epoch 7 - train_f1_at_03:0.21488  valid_f1_at_03:0.50607\n","Epoch 7 - train_f1_at_05:0.03221  valid_f1_at_05:0.28403\n","Starting 8 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [16:31<00:00,  1.33s/it, loss=0.00604]\n","100%|| 93/93 [01:12<00:00,  1.28it/s, loss=0.00479]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 - avg_train_loss: 0.00604  avg_val_loss: 0.00479  time: 1065s\n","Epoch 8 - train_f1_at_03:0.24420  valid_f1_at_03:0.51208\n","Epoch 8 - train_f1_at_05:0.04246  valid_f1_at_05:0.29200\n","Starting 9 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [17:25<00:00,  1.41s/it, loss=0.00601]\n","100%|| 93/93 [01:15<00:00,  1.23it/s, loss=0.00406]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9 - avg_train_loss: 0.00601  avg_val_loss: 0.00406  time: 1122s\n","Epoch 9 - train_f1_at_03:0.25487  valid_f1_at_03:0.59599\n","Epoch 9 - train_f1_at_05:0.04910  valid_f1_at_05:0.39254\n",">>>>>>>> Model Improved From 0.5297962322183776 ----> 0.5959948557780635\n","other scores here... 0.5959948557780635, 0.39254123834568494\n","Starting 10 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [17:35<00:00,  1.42s/it, loss=0.00598]\n","100%|| 93/93 [01:14<00:00,  1.26it/s, loss=0.00395]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10 - avg_train_loss: 0.00598  avg_val_loss: 0.00395  time: 1130s\n","Epoch 10 - train_f1_at_03:0.25676  valid_f1_at_03:0.60803\n","Epoch 10 - train_f1_at_05:0.04731  valid_f1_at_05:0.39579\n",">>>>>>>> Model Improved From 0.5959948557780635 ----> 0.6080291970802919\n","other scores here... 0.6080291970802919, 0.3957884661402249\n","Starting 11 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [17:15<00:00,  1.39s/it, loss=0.00581]\n","100%|| 93/93 [01:14<00:00,  1.25it/s, loss=0.00424]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11 - avg_train_loss: 0.00581  avg_val_loss: 0.00424  time: 1110s\n","Epoch 11 - train_f1_at_03:0.28034  valid_f1_at_03:0.58888\n","Epoch 11 - train_f1_at_05:0.05382  valid_f1_at_05:0.33243\n","Starting 12 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [17:19<00:00,  1.40s/it, loss=0.00542]\n","100%|| 93/93 [01:19<00:00,  1.17it/s, loss=0.00412]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12 - avg_train_loss: 0.00542  avg_val_loss: 0.00412  time: 1120s\n","Epoch 12 - train_f1_at_03:0.33280  valid_f1_at_03:0.60271\n","Epoch 12 - train_f1_at_05:0.08161  valid_f1_at_05:0.40509\n","Starting 13 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [16:01<00:00,  1.29s/it, loss=0.00554]\n","100%|| 93/93 [01:05<00:00,  1.42it/s, loss=0.00361]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13 - avg_train_loss: 0.00554  avg_val_loss: 0.00361  time: 1027s\n","Epoch 13 - train_f1_at_03:0.31431  valid_f1_at_03:0.66442\n","Epoch 13 - train_f1_at_05:0.07515  valid_f1_at_05:0.42700\n",">>>>>>>> Model Improved From 0.6080291970802919 ----> 0.6644176136363636\n","other scores here... 0.6644176136363636, 0.42699789078978206\n","Starting 14 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:07<00:00,  1.22s/it, loss=0.0055] \n","100%|| 93/93 [01:06<00:00,  1.41it/s, loss=0.0036] \n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14 - avg_train_loss: 0.00550  avg_val_loss: 0.00360  time: 974s\n","Epoch 14 - train_f1_at_03:0.32818  valid_f1_at_03:0.66384\n","Epoch 14 - train_f1_at_05:0.08083  valid_f1_at_05:0.45072\n","Starting 15 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:08<00:00,  1.22s/it, loss=0.00524]\n","100%|| 93/93 [01:04<00:00,  1.44it/s, loss=0.00398]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15 - avg_train_loss: 0.00524  avg_val_loss: 0.00398  time: 973s\n","Epoch 15 - train_f1_at_03:0.35806  valid_f1_at_03:0.62286\n","Epoch 15 - train_f1_at_05:0.09951  valid_f1_at_05:0.34117\n","Starting 16 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:09<00:00,  1.22s/it, loss=0.00506]\n","100%|| 93/93 [01:04<00:00,  1.43it/s, loss=0.00382]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16 - avg_train_loss: 0.00506  avg_val_loss: 0.00382  time: 975s\n","Epoch 16 - train_f1_at_03:0.39373  valid_f1_at_03:0.63638\n","Epoch 16 - train_f1_at_05:0.11813  valid_f1_at_05:0.38754\n","Starting 17 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:07<00:00,  1.22s/it, loss=0.00525]\n","100%|| 93/93 [01:05<00:00,  1.42it/s, loss=0.00336]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17 - avg_train_loss: 0.00525  avg_val_loss: 0.00336  time: 973s\n","Epoch 17 - train_f1_at_03:0.34759  valid_f1_at_03:0.69029\n","Epoch 17 - train_f1_at_05:0.10044  valid_f1_at_05:0.43753\n",">>>>>>>> Model Improved From 0.6644176136363636 ----> 0.6902873259298431\n","other scores here... 0.6902873259298431, 0.4375292466073935\n","Starting 18 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:09<00:00,  1.22s/it, loss=0.00513]\n","100%|| 93/93 [01:08<00:00,  1.36it/s, loss=0.00335]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18 - avg_train_loss: 0.00513  avg_val_loss: 0.00335  time: 979s\n","Epoch 18 - train_f1_at_03:0.36473  valid_f1_at_03:0.68803\n","Epoch 18 - train_f1_at_05:0.10551  valid_f1_at_05:0.49268\n","Starting 19 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:06<00:00,  1.22s/it, loss=0.00338]\n","100%|| 93/93 [01:04<00:00,  1.45it/s, loss=0.00414]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19 - avg_train_loss: 0.00338  avg_val_loss: 0.00414  time: 971s\n","Epoch 19 - train_f1_at_03:0.68649  valid_f1_at_03:0.61525\n","Epoch 19 - train_f1_at_05:0.47634  valid_f1_at_05:0.49989\n","Starting 20 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:06<00:00,  1.22s/it, loss=0.00317]\n","100%|| 93/93 [01:03<00:00,  1.46it/s, loss=0.00391]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20 - avg_train_loss: 0.00317  avg_val_loss: 0.00391  time: 971s\n","Epoch 20 - train_f1_at_03:0.70540  valid_f1_at_03:0.65639\n","Epoch 20 - train_f1_at_05:0.55463  valid_f1_at_05:0.59867\n","Starting 21 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:02<00:00,  1.21s/it, loss=0.00337]\n","100%|| 93/93 [01:03<00:00,  1.45it/s, loss=0.00338]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 21 - avg_train_loss: 0.00337  avg_val_loss: 0.00338  time: 967s\n","Epoch 21 - train_f1_at_03:0.68990  valid_f1_at_03:0.70166\n","Epoch 21 - train_f1_at_05:0.52569  valid_f1_at_05:0.65569\n",">>>>>>>> Model Improved From 0.6902873259298431 ----> 0.7016611295681063\n","other scores here... 0.7016611295681063, 0.6556927297668039\n","Starting 22 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:02<00:00,  1.21s/it, loss=0.00317]\n","100%|| 93/93 [01:04<00:00,  1.44it/s, loss=0.00336]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 22 - avg_train_loss: 0.00317  avg_val_loss: 0.00336  time: 968s\n","Epoch 22 - train_f1_at_03:0.70776  valid_f1_at_03:0.71266\n","Epoch 22 - train_f1_at_05:0.56314  valid_f1_at_05:0.66251\n",">>>>>>>> Model Improved From 0.7016611295681063 ----> 0.7126550868486352\n","other scores here... 0.7126550868486352, 0.6625073113667381\n","Starting 23 epoch...\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 743/743 [15:04<00:00,  1.22s/it, loss=0.00283]\n","100%|| 93/93 [01:03<00:00,  1.45it/s, loss=0.00396]"]},{"name":"stdout","output_type":"stream","text":["Epoch 23 - avg_train_loss: 0.00283  avg_val_loss: 0.00396  time: 969s\n","Epoch 23 - train_f1_at_03:0.74553  valid_f1_at_03:0.64613\n","Epoch 23 - train_f1_at_05:0.61830  valid_f1_at_05:0.57078\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# main loop\n","for fold in range(5):\n","    if fold not in CFG.folds:\n","        continue\n","    print(\"=\" * 100)\n","    print(f\"Fold {fold} Training\")\n","    print(\"=\" * 100)\n","\n","    trn_df = train[train.kfold != fold].reset_index(drop=True)\n","    val_df = train[train.kfold == fold].reset_index(drop=True)\n","\n","    train_dataset = WaveformDataset(df=trn_df, mode='train')\n","    train_dataloader = torch.utils.data.DataLoader(\n","        train_dataset, batch_size=CFG.train_bs, num_workers=0, pin_memory=True, shuffle=True\n","    )\n","    \n","    valid_dataset = WaveformDataset(df=val_df, mode='valid')\n","    valid_dataloader = torch.utils.data.DataLoader(\n","        valid_dataset, batch_size=CFG.valid_bs, num_workers=0, pin_memory=True, shuffle=False\n","    )\n","\n","    model = TimmSED(\n","        base_model_name=CFG.base_model_name,\n","        pretrained=CFG.pretrained,\n","        num_classes=CFG.num_classes,\n","        in_channels=CFG.in_channels)\n","\n","    optimizer = transformers.AdamW(model.parameters(), lr=CFG.LR, weight_decay=CFG.WEIGHT_DECAY)\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=CFG.ETA_MIN, T_max=500)\n","\n","    model = model.to(device)\n","\n","    min_loss = 999\n","    best_score = -np.inf\n","\n","    for epoch in range(CFG.epochs):\n","        print(\"Starting {} epoch...\".format(epoch+1))\n","\n","        start_time = time.time()\n","\n","        if epoch < CFG.cutmix_and_mixup_epochs:\n","            train_avg, train_loss = train_mixup_cutmix_fn(model, train_dataloader, device, optimizer, scheduler)\n","        else: \n","            train_avg, train_loss = train_fn(model, train_dataloader, device, optimizer, scheduler)\n","\n","        valid_avg, valid_loss = valid_fn(model, valid_dataloader, device)\n","\n","        elapsed = time.time() - start_time\n","\n","        print(f'Epoch {epoch+1} - avg_train_loss: {train_loss:.5f}  avg_val_loss: {valid_loss:.5f}  time: {elapsed:.0f}s')\n","        print(f\"Epoch {epoch+1} - train_f1_at_03:{train_avg['f1_at_03']:0.5f}  valid_f1_at_03:{valid_avg['f1_at_03']:0.5f}\")\n","        print(f\"Epoch {epoch+1} - train_f1_at_05:{train_avg['f1_at_05']:0.5f}  valid_f1_at_05:{valid_avg['f1_at_05']:0.5f}\")\n","\n","        if valid_avg['f1_at_03'] > best_score:\n","            print(f\">>>>>>>> Model Improved From {best_score} ----> {valid_avg['f1_at_03']}\")\n","            print(f\"other scores here... {valid_avg['f1_at_03']}, {valid_avg['f1_at_05']}\")\n","            torch.save(model.state_dict(), f'fold-{fold}.bin')\n","            best_score = valid_avg['f1_at_03']"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|| 93/93 [01:03<00:00,  1.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["micro f1_0.3 0.699205823957644\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 93/93 [01:03<00:00,  1.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["micro f1_0.3 0.7047823928512328\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 93/93 [01:02<00:00,  1.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["micro f1_0.3 0.7055711687882295\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 93/93 [01:02<00:00,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["micro f1_0.3 0.7059357714851812\n"]},{"name":"stderr","output_type":"stream","text":["100%|| 93/93 [01:02<00:00,  1.49it/s]\n"]},{"name":"stdout","output_type":"stream","text":["micro f1_0.3 0.7072775924151827\n","overall micro f1_0.3 0.7072775924151827\n","overall micro f1_0.5 0.6582853562056946\n"]}],"source":["model_paths = [f'fold-{i}.bin' for i in CFG.folds]\n","\n","calc_cv(model_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"interpreter":{"hash":"ccd939c93ab068b4b58227f04d922ef82bb8e88e5b6f5613cfc27fa317c2006f"},"kernelspec":{"display_name":"Python 3.9.1 ('AudioML_3060')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"}},"nbformat":4,"nbformat_minor":4}
